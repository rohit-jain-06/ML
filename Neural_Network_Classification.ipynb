{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohit-jain-06/ML/blob/main/Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 â€“ Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10fefb8-9155-424d-9ed4-ec7fcf681e15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "0b0433b2-1e24-4571-9b58-091660844131"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0140e822-d41a-4a97-8c19-65d1c21631a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 03.jpg\n",
            " 1606636721054.jpg\n",
            "'1. NQueens for 4 Queens Code.docx'\n",
            "'3. Control Structure.gdoc'\n",
            "'ADA Unit-4.gdoc'\n",
            "'ADA Unit-4.pdf'\n",
            "'Alexa skill set Password keeper (1).rtf'\n",
            "'Alexa skill set Password keeper (1).txt.rtf'\n",
            "'Alexa skill set Password keeper (2).txt.rtf'\n",
            "'alexa skill set password keeper.jpg'\n",
            "'Alexa skill set Password keeper.rtf'\n",
            "'Alexa skill set password keeper.txt'\n",
            "'Alexa skill set Password keeper.txt.rtf'\n",
            "'Attendance (1).gsheet'\n",
            "'Attendance (2).gsheet'\n",
            " Attendance.gsheet\n",
            " Business-Model-Canvas.docx\n",
            " Business-Model-Canvas.gdoc\n",
            "'c1 (1).jpg'\n",
            " c1.jpg\n",
            "'c2 (1).jpg'\n",
            " c2.jpg\n",
            "'c3 (1).jpg'\n",
            " c3.jpg\n",
            " cc1.jpg\n",
            "'certificate (1).pdf'\n",
            " Classroom\n",
            "'CO II Year Attendance August (1).gsheet'\n",
            "'Colab Notebooks'\n",
            "'covid 19 pledge ROHIT JAIN.docx'\n",
            "'CSIT-1st yr.xlsx'\n",
            "'CSO assignment '\n",
            " CSS.gdoc\n",
            "'Cybersecurity_Foundation_Student_Certificate Paloalto (1).pdf'\n",
            "'Cybersecurity_Foundation_Student_Certificate Paloalto.pdf'\n",
            "'cybrary -cybersecurity ROHIT JAIN CO 48 (1).pdf'\n",
            "'cybrary -cybersecurity ROHIT JAIN CO 48.pdf'\n",
            "'Data Analytics.gslides'\n",
            "'DATA STRUCTURES'\n",
            "'Day 2 OOPS Concept (16-07-2020) (1).gslides'\n",
            "'Day 2 OOPS Concept (16-07-2020).gslides'\n",
            "'Day 2 OOPS Concept (16-07-2020).pptx'\n",
            " diabetes.csv\n",
            "'DS ASS 0101.pdf'\n",
            " _DSC0045.JPG\n",
            " _DSC0046.JPG\n",
            " _DSC0047.JPG\n",
            " DSC_1094.MOV\n",
            "'DS L1,2,3 (1).gdoc'\n",
            "'DS L1,2,3.gdoc'\n",
            " E4.jpg\n",
            " ECO-NURTURES.pdf\n",
            "'Entrepreneurship Development Cell (EDC).gdoc'\n",
            "'E-Summit2021 photos'\n",
            "'Evolution of SW economy.gslides'\n",
            "'Exit Ticket (Responses).gsheet'\n",
            "'FILE HANDLING ROHIT JAIN(48) SHREYA SHARMA (55).pptx'\n",
            "'First Unit DBMS PPT.gslides'\n",
            "'Fractional Knapsack CO-48.pdf'\n",
            "'G6- Library Management System.docx'\n",
            "'G6- LIBRARY MANAGEMENT SYSTEM SRS (G-6) (1).docx'\n",
            "'Getting started.pdf'\n",
            "'hackerrank certificate.jpg'\n",
            " IMG_20210123_214814.jpg\n",
            " IMG_20210325_171510_110.jpg\n",
            " IMG_3113.JPG\n",
            "'IWT Assignment '\n",
            "'IWT - CO.gdoc'\n",
            "'JAY PAL CO-27 friends functions.pptx'\n",
            "'Lab analysis report CO-48.gdoc'\n",
            "'Lecture  13-  Neural Network (Forward and Backward Calculation).gslides'\n",
            " Linux-1.gdoc\n",
            "'Linux Unit 2.gslides'\n",
            " Parent_AFD_2293978_2812202017048339.pdf\n",
            " petrol_consumption.xls\n",
            "'PROTOTYPE VIDEO '\n",
            "'QUICK SORT PRACTICAL {CO-48}.pdf'\n",
            "'Rohit Jain co-48 ADA Assignment.pdf'\n",
            "'ROHIT JAIN (CO-48) ADA PRACTICAL FILE.gdoc'\n",
            "'Rohit jain CO factorial using class.pdf'\n",
            "'Rohit Jain Resume.pdf'\n",
            " s1.jpg\n",
            " s2.jpg\n",
            "'Screenshot_2020-06-14-10-11-20-652_com (1).miui.gallery.jpg'\n",
            " Screenshot_2020-06-14-10-11-20-652_com.miui.gallery.jpg\n",
            " Screenshot_2021-07-24-13-34-46-935_com.cisco.webex.meetings.jpg\n",
            " Screenshot_2021-08-06-11-47-51-209_com.google.android.apps.meetings.jpg\n",
            "'Sleep Command.gdoc'\n",
            "'Software Processes.gdoc'\n",
            "'Software Testing.gdoc'\n",
            " Student_AFD_2293978_2812202017048196.pdf\n",
            " TOC_Practical_assessment_format.gdoc\n",
            "'Unit Test Paper.gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'UPDATED DBMS PPT (1) (1).gslides'\n",
            "'UPDATED DBMS PPT (1) (2).gslides'\n",
            "'UPDATED DBMS PPT (1).gslides'\n",
            "'VID_20200809_224230 (1).mp4'\n",
            "'WhatsApp Image 2020-11-07 at 1.07.09 PM.jpeg'\n",
            "'WhatsApp Image 2020-11-07 at 5.47.56 PM.jpeg'\n",
            "'WhatsApp Image 2021-02-07 at 1.27.34 PM (1).jpeg'\n",
            "'WhatsApp Image 2021-02-07 at 1.27.34 PM (2).jpeg'\n",
            "'WhatsApp Image 2021-02-07 at 1.27.34 PM.jpeg'\n",
            "'WhatsApp Image 2021-02-10 at 3.24.35 PM.jpeg'\n",
            "'WhatsApp Image 2021-05-31 at 12.25.41 PM.jpeg'\n",
            "'WhatsApp Image 2021-09-15 at 12.16.52 PM.jpeg'\n",
            "'WhatsApp Image 2021-09-24 at 10.32.51 AM.jpeg'\n",
            "'WhatsApp Image 2021-09-24 at 10.35.36 AM.jpeg'\n",
            "'WhatsApp Image 2021-09-24 at 11.14.54 AM.jpeg'\n",
            "'WhatsApp Image 2021-10-05 at 4.26.04 PM.jpeg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "211bfc82-8d50-427b-b0f9-7efc87c3463d"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0d15d2d-58ca-40a2-a505-d8a2763e24e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0d15d2d-58ca-40a2-a505-d8a2763e24e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0d15d2d-58ca-40a2-a505-d8a2763e24e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0d15d2d-58ca-40a2-a505-d8a2763e24e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "197a29e4-e562-4f38-c39a-92b233b0f7fe"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "8a457906-458b-4627-81f3-af22ac31c241"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "14f1adfa-7db1-40a0-bbbd-070a27f91c30"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "760d6f65-eb7d-4ea6-a5f2-f7acae3121e2"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "f4b27221-a607-4521-985e-a0a473a8021b"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "15014a83-2ede-4b38-c637-a020c14368b8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.1, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "552\n",
            "77\n",
            "139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNfmvbMOXeku"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "df790fd2-f9a8-4d8a-933b-79265a79f01e"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=1000, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7717 - val_loss: 0.4763 - val_accuracy: 0.7698\n",
            "Epoch 2/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7663 - val_loss: 0.4730 - val_accuracy: 0.7770\n",
            "Epoch 3/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7717 - val_loss: 0.4732 - val_accuracy: 0.7770\n",
            "Epoch 4/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7663 - val_loss: 0.4727 - val_accuracy: 0.7770\n",
            "Epoch 5/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7736 - val_loss: 0.4723 - val_accuracy: 0.7770\n",
            "Epoch 6/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7663 - val_loss: 0.4706 - val_accuracy: 0.7770\n",
            "Epoch 7/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7663 - val_loss: 0.4740 - val_accuracy: 0.7698\n",
            "Epoch 8/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7736 - val_loss: 0.4699 - val_accuracy: 0.7770\n",
            "Epoch 9/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7826 - val_loss: 0.4798 - val_accuracy: 0.7698\n",
            "Epoch 10/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7681 - val_loss: 0.4733 - val_accuracy: 0.7698\n",
            "Epoch 11/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7699 - val_loss: 0.4803 - val_accuracy: 0.7698\n",
            "Epoch 12/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7681 - val_loss: 0.4766 - val_accuracy: 0.7698\n",
            "Epoch 13/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7627 - val_loss: 0.4769 - val_accuracy: 0.7698\n",
            "Epoch 14/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7736 - val_loss: 0.4699 - val_accuracy: 0.7770\n",
            "Epoch 15/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7681 - val_loss: 0.4711 - val_accuracy: 0.7698\n",
            "Epoch 16/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7790 - val_loss: 0.4826 - val_accuracy: 0.7698\n",
            "Epoch 17/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7717 - val_loss: 0.4770 - val_accuracy: 0.7698\n",
            "Epoch 18/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7681 - val_loss: 0.4782 - val_accuracy: 0.7698\n",
            "Epoch 19/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7699 - val_loss: 0.4744 - val_accuracy: 0.7698\n",
            "Epoch 20/1000\n",
            "138/138 [==============================] - 1s 4ms/step - loss: 0.4574 - accuracy: 0.7717 - val_loss: 0.4763 - val_accuracy: 0.7698\n",
            "Epoch 21/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7717 - val_loss: 0.4783 - val_accuracy: 0.7698\n",
            "Epoch 22/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7663 - val_loss: 0.4757 - val_accuracy: 0.7698\n",
            "Epoch 23/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7772 - val_loss: 0.4780 - val_accuracy: 0.7698\n",
            "Epoch 24/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7699 - val_loss: 0.4745 - val_accuracy: 0.7698\n",
            "Epoch 25/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7754 - val_loss: 0.4683 - val_accuracy: 0.7842\n",
            "Epoch 26/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7717 - val_loss: 0.4713 - val_accuracy: 0.7770\n",
            "Epoch 27/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7681 - val_loss: 0.4694 - val_accuracy: 0.7770\n",
            "Epoch 28/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7699 - val_loss: 0.4675 - val_accuracy: 0.7842\n",
            "Epoch 29/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7645 - val_loss: 0.4683 - val_accuracy: 0.7770\n",
            "Epoch 30/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7681 - val_loss: 0.4724 - val_accuracy: 0.7770\n",
            "Epoch 31/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7754 - val_loss: 0.4763 - val_accuracy: 0.7698\n",
            "Epoch 32/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7736 - val_loss: 0.4724 - val_accuracy: 0.7770\n",
            "Epoch 33/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7717 - val_loss: 0.4716 - val_accuracy: 0.7770\n",
            "Epoch 34/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7790 - val_loss: 0.4836 - val_accuracy: 0.7626\n",
            "Epoch 35/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7717 - val_loss: 0.4722 - val_accuracy: 0.7770\n",
            "Epoch 36/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7717 - val_loss: 0.4700 - val_accuracy: 0.7770\n",
            "Epoch 37/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7736 - val_loss: 0.4692 - val_accuracy: 0.7770\n",
            "Epoch 38/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7736 - val_loss: 0.4737 - val_accuracy: 0.7770\n",
            "Epoch 39/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7699 - val_loss: 0.4794 - val_accuracy: 0.7626\n",
            "Epoch 40/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7736 - val_loss: 0.4682 - val_accuracy: 0.7770\n",
            "Epoch 41/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7681 - val_loss: 0.4678 - val_accuracy: 0.7770\n",
            "Epoch 42/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7681 - val_loss: 0.4693 - val_accuracy: 0.7770\n",
            "Epoch 43/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7699 - val_loss: 0.4670 - val_accuracy: 0.7770\n",
            "Epoch 44/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7699 - val_loss: 0.4677 - val_accuracy: 0.7770\n",
            "Epoch 45/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7681 - val_loss: 0.4705 - val_accuracy: 0.7770\n",
            "Epoch 46/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7663 - val_loss: 0.4706 - val_accuracy: 0.7770\n",
            "Epoch 47/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7681 - val_loss: 0.4700 - val_accuracy: 0.7770\n",
            "Epoch 48/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7699 - val_loss: 0.4695 - val_accuracy: 0.7770\n",
            "Epoch 49/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7663 - val_loss: 0.4689 - val_accuracy: 0.7770\n",
            "Epoch 50/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7717 - val_loss: 0.4691 - val_accuracy: 0.7770\n",
            "Epoch 51/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7663 - val_loss: 0.4663 - val_accuracy: 0.7770\n",
            "Epoch 52/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7736 - val_loss: 0.4732 - val_accuracy: 0.7698\n",
            "Epoch 53/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7717 - val_loss: 0.4680 - val_accuracy: 0.7770\n",
            "Epoch 54/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7717 - val_loss: 0.4682 - val_accuracy: 0.7770\n",
            "Epoch 55/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7663 - val_loss: 0.4673 - val_accuracy: 0.7770\n",
            "Epoch 56/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7717 - val_loss: 0.4794 - val_accuracy: 0.7698\n",
            "Epoch 57/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7736 - val_loss: 0.4737 - val_accuracy: 0.7698\n",
            "Epoch 58/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7736 - val_loss: 0.4723 - val_accuracy: 0.7698\n",
            "Epoch 59/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7736 - val_loss: 0.4675 - val_accuracy: 0.7770\n",
            "Epoch 60/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7717 - val_loss: 0.4761 - val_accuracy: 0.7698\n",
            "Epoch 61/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7663 - val_loss: 0.4715 - val_accuracy: 0.7698\n",
            "Epoch 62/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7717 - val_loss: 0.4710 - val_accuracy: 0.7698\n",
            "Epoch 63/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7772 - val_loss: 0.4687 - val_accuracy: 0.7770\n",
            "Epoch 64/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7754 - val_loss: 0.4651 - val_accuracy: 0.7770\n",
            "Epoch 65/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7717 - val_loss: 0.4741 - val_accuracy: 0.7698\n",
            "Epoch 66/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7681 - val_loss: 0.4742 - val_accuracy: 0.7698\n",
            "Epoch 67/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7736 - val_loss: 0.4777 - val_accuracy: 0.7698\n",
            "Epoch 68/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7754 - val_loss: 0.4764 - val_accuracy: 0.7698\n",
            "Epoch 69/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7772 - val_loss: 0.4713 - val_accuracy: 0.7698\n",
            "Epoch 70/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7736 - val_loss: 0.4708 - val_accuracy: 0.7698\n",
            "Epoch 71/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7772 - val_loss: 0.4717 - val_accuracy: 0.7698\n",
            "Epoch 72/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7663 - val_loss: 0.4694 - val_accuracy: 0.7698\n",
            "Epoch 73/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7736 - val_loss: 0.4710 - val_accuracy: 0.7698\n",
            "Epoch 74/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7754 - val_loss: 0.4814 - val_accuracy: 0.7698\n",
            "Epoch 75/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7736 - val_loss: 0.4724 - val_accuracy: 0.7698\n",
            "Epoch 76/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7790 - val_loss: 0.4642 - val_accuracy: 0.7770\n",
            "Epoch 77/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7736 - val_loss: 0.4703 - val_accuracy: 0.7698\n",
            "Epoch 78/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7717 - val_loss: 0.4678 - val_accuracy: 0.7770\n",
            "Epoch 79/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7717 - val_loss: 0.4718 - val_accuracy: 0.7698\n",
            "Epoch 80/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7736 - val_loss: 0.4702 - val_accuracy: 0.7698\n",
            "Epoch 81/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7754 - val_loss: 0.4722 - val_accuracy: 0.7698\n",
            "Epoch 82/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7717 - val_loss: 0.4713 - val_accuracy: 0.7698\n",
            "Epoch 83/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7681 - val_loss: 0.4726 - val_accuracy: 0.7698\n",
            "Epoch 84/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7754 - val_loss: 0.4711 - val_accuracy: 0.7698\n",
            "Epoch 85/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7717 - val_loss: 0.4685 - val_accuracy: 0.7698\n",
            "Epoch 86/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7717 - val_loss: 0.4669 - val_accuracy: 0.7770\n",
            "Epoch 87/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7681 - val_loss: 0.4649 - val_accuracy: 0.7770\n",
            "Epoch 88/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7736 - val_loss: 0.4689 - val_accuracy: 0.7698\n",
            "Epoch 89/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7790 - val_loss: 0.4697 - val_accuracy: 0.7698\n",
            "Epoch 90/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7736 - val_loss: 0.4721 - val_accuracy: 0.7698\n",
            "Epoch 91/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7736 - val_loss: 0.4704 - val_accuracy: 0.7698\n",
            "Epoch 92/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7754 - val_loss: 0.4703 - val_accuracy: 0.7698\n",
            "Epoch 93/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7736 - val_loss: 0.4660 - val_accuracy: 0.7770\n",
            "Epoch 94/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7826 - val_loss: 0.4616 - val_accuracy: 0.7698\n",
            "Epoch 95/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7699 - val_loss: 0.4718 - val_accuracy: 0.7698\n",
            "Epoch 96/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7754 - val_loss: 0.4703 - val_accuracy: 0.7698\n",
            "Epoch 97/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7754 - val_loss: 0.4666 - val_accuracy: 0.7770\n",
            "Epoch 98/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7717 - val_loss: 0.4688 - val_accuracy: 0.7770\n",
            "Epoch 99/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7754 - val_loss: 0.4633 - val_accuracy: 0.7770\n",
            "Epoch 100/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7754 - val_loss: 0.4681 - val_accuracy: 0.7770\n",
            "Epoch 101/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7663 - val_loss: 0.4679 - val_accuracy: 0.7770\n",
            "Epoch 102/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7754 - val_loss: 0.4673 - val_accuracy: 0.7770\n",
            "Epoch 103/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7754 - val_loss: 0.4680 - val_accuracy: 0.7770\n",
            "Epoch 104/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7736 - val_loss: 0.4693 - val_accuracy: 0.7698\n",
            "Epoch 105/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7754 - val_loss: 0.4685 - val_accuracy: 0.7770\n",
            "Epoch 106/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7717 - val_loss: 0.4706 - val_accuracy: 0.7698\n",
            "Epoch 107/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7772 - val_loss: 0.4746 - val_accuracy: 0.7626\n",
            "Epoch 108/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7754 - val_loss: 0.4770 - val_accuracy: 0.7626\n",
            "Epoch 109/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7736 - val_loss: 0.4659 - val_accuracy: 0.7770\n",
            "Epoch 110/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7790 - val_loss: 0.4687 - val_accuracy: 0.7698\n",
            "Epoch 111/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7754 - val_loss: 0.4757 - val_accuracy: 0.7626\n",
            "Epoch 112/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7736 - val_loss: 0.4680 - val_accuracy: 0.7698\n",
            "Epoch 113/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7826 - val_loss: 0.4723 - val_accuracy: 0.7626\n",
            "Epoch 114/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7772 - val_loss: 0.4688 - val_accuracy: 0.7698\n",
            "Epoch 115/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7772 - val_loss: 0.4660 - val_accuracy: 0.7770\n",
            "Epoch 116/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7844 - val_loss: 0.4695 - val_accuracy: 0.7698\n",
            "Epoch 117/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7772 - val_loss: 0.4735 - val_accuracy: 0.7626\n",
            "Epoch 118/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7772 - val_loss: 0.4665 - val_accuracy: 0.7770\n",
            "Epoch 119/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7754 - val_loss: 0.4698 - val_accuracy: 0.7698\n",
            "Epoch 120/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7790 - val_loss: 0.4706 - val_accuracy: 0.7626\n",
            "Epoch 121/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7772 - val_loss: 0.4654 - val_accuracy: 0.7770\n",
            "Epoch 122/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7754 - val_loss: 0.4691 - val_accuracy: 0.7626\n",
            "Epoch 123/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7717 - val_loss: 0.4724 - val_accuracy: 0.7626\n",
            "Epoch 124/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7808 - val_loss: 0.4670 - val_accuracy: 0.7698\n",
            "Epoch 125/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7736 - val_loss: 0.4679 - val_accuracy: 0.7626\n",
            "Epoch 126/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7717 - val_loss: 0.4732 - val_accuracy: 0.7626\n",
            "Epoch 127/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7736 - val_loss: 0.4706 - val_accuracy: 0.7626\n",
            "Epoch 128/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7736 - val_loss: 0.4671 - val_accuracy: 0.7626\n",
            "Epoch 129/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7717 - val_loss: 0.4727 - val_accuracy: 0.7626\n",
            "Epoch 130/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7736 - val_loss: 0.4698 - val_accuracy: 0.7626\n",
            "Epoch 131/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7736 - val_loss: 0.4578 - val_accuracy: 0.7914\n",
            "Epoch 132/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7808 - val_loss: 0.4721 - val_accuracy: 0.7626\n",
            "Epoch 133/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7754 - val_loss: 0.4693 - val_accuracy: 0.7626\n",
            "Epoch 134/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7754 - val_loss: 0.4751 - val_accuracy: 0.7626\n",
            "Epoch 135/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7754 - val_loss: 0.4769 - val_accuracy: 0.7554\n",
            "Epoch 136/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7790 - val_loss: 0.4717 - val_accuracy: 0.7626\n",
            "Epoch 137/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7844 - val_loss: 0.4751 - val_accuracy: 0.7626\n",
            "Epoch 138/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7844 - val_loss: 0.4690 - val_accuracy: 0.7626\n",
            "Epoch 139/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7808 - val_loss: 0.4702 - val_accuracy: 0.7626\n",
            "Epoch 140/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7790 - val_loss: 0.4673 - val_accuracy: 0.7626\n",
            "Epoch 141/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7717 - val_loss: 0.4697 - val_accuracy: 0.7626\n",
            "Epoch 142/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7772 - val_loss: 0.4633 - val_accuracy: 0.7698\n",
            "Epoch 143/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7772 - val_loss: 0.4633 - val_accuracy: 0.7698\n",
            "Epoch 144/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7772 - val_loss: 0.4659 - val_accuracy: 0.7698\n",
            "Epoch 145/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7772 - val_loss: 0.4745 - val_accuracy: 0.7626\n",
            "Epoch 146/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7772 - val_loss: 0.4645 - val_accuracy: 0.7626\n",
            "Epoch 147/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7808 - val_loss: 0.4636 - val_accuracy: 0.7698\n",
            "Epoch 148/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7754 - val_loss: 0.4669 - val_accuracy: 0.7626\n",
            "Epoch 149/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7826 - val_loss: 0.4708 - val_accuracy: 0.7626\n",
            "Epoch 150/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7736 - val_loss: 0.4666 - val_accuracy: 0.7626\n",
            "Epoch 151/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7808 - val_loss: 0.4643 - val_accuracy: 0.7626\n",
            "Epoch 152/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7772 - val_loss: 0.4742 - val_accuracy: 0.7626\n",
            "Epoch 153/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7772 - val_loss: 0.4652 - val_accuracy: 0.7626\n",
            "Epoch 154/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7826 - val_loss: 0.4682 - val_accuracy: 0.7626\n",
            "Epoch 155/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7826 - val_loss: 0.4620 - val_accuracy: 0.7770\n",
            "Epoch 156/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7844 - val_loss: 0.4623 - val_accuracy: 0.7698\n",
            "Epoch 157/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7862 - val_loss: 0.4640 - val_accuracy: 0.7698\n",
            "Epoch 158/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7754 - val_loss: 0.4652 - val_accuracy: 0.7626\n",
            "Epoch 159/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7790 - val_loss: 0.4620 - val_accuracy: 0.7698\n",
            "Epoch 160/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7808 - val_loss: 0.4692 - val_accuracy: 0.7626\n",
            "Epoch 161/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7754 - val_loss: 0.4716 - val_accuracy: 0.7626\n",
            "Epoch 162/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7772 - val_loss: 0.4659 - val_accuracy: 0.7626\n",
            "Epoch 163/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7826 - val_loss: 0.4649 - val_accuracy: 0.7626\n",
            "Epoch 164/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7772 - val_loss: 0.4704 - val_accuracy: 0.7626\n",
            "Epoch 165/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7790 - val_loss: 0.4681 - val_accuracy: 0.7626\n",
            "Epoch 166/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7808 - val_loss: 0.4644 - val_accuracy: 0.7626\n",
            "Epoch 167/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7880 - val_loss: 0.4637 - val_accuracy: 0.7698\n",
            "Epoch 168/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7808 - val_loss: 0.4643 - val_accuracy: 0.7626\n",
            "Epoch 169/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7826 - val_loss: 0.4741 - val_accuracy: 0.7554\n",
            "Epoch 170/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7754 - val_loss: 0.4762 - val_accuracy: 0.7554\n",
            "Epoch 171/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7790 - val_loss: 0.4708 - val_accuracy: 0.7626\n",
            "Epoch 172/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7754 - val_loss: 0.4683 - val_accuracy: 0.7626\n",
            "Epoch 173/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7754 - val_loss: 0.4620 - val_accuracy: 0.7698\n",
            "Epoch 174/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7790 - val_loss: 0.4613 - val_accuracy: 0.7698\n",
            "Epoch 175/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7808 - val_loss: 0.4661 - val_accuracy: 0.7626\n",
            "Epoch 176/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7808 - val_loss: 0.4650 - val_accuracy: 0.7626\n",
            "Epoch 177/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7844 - val_loss: 0.4706 - val_accuracy: 0.7626\n",
            "Epoch 178/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7826 - val_loss: 0.4689 - val_accuracy: 0.7626\n",
            "Epoch 179/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7808 - val_loss: 0.4678 - val_accuracy: 0.7626\n",
            "Epoch 180/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7790 - val_loss: 0.4638 - val_accuracy: 0.7626\n",
            "Epoch 181/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7862 - val_loss: 0.4730 - val_accuracy: 0.7554\n",
            "Epoch 182/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7844 - val_loss: 0.4688 - val_accuracy: 0.7626\n",
            "Epoch 183/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7790 - val_loss: 0.4619 - val_accuracy: 0.7698\n",
            "Epoch 184/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7790 - val_loss: 0.4587 - val_accuracy: 0.7842\n",
            "Epoch 185/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7826 - val_loss: 0.4580 - val_accuracy: 0.7842\n",
            "Epoch 186/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7826 - val_loss: 0.4713 - val_accuracy: 0.7626\n",
            "Epoch 187/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7826 - val_loss: 0.4708 - val_accuracy: 0.7626\n",
            "Epoch 188/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7754 - val_loss: 0.4607 - val_accuracy: 0.7698\n",
            "Epoch 189/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7862 - val_loss: 0.4635 - val_accuracy: 0.7626\n",
            "Epoch 190/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7772 - val_loss: 0.4703 - val_accuracy: 0.7626\n",
            "Epoch 191/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7790 - val_loss: 0.4702 - val_accuracy: 0.7626\n",
            "Epoch 192/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7862 - val_loss: 0.4728 - val_accuracy: 0.7554\n",
            "Epoch 193/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7844 - val_loss: 0.4727 - val_accuracy: 0.7554\n",
            "Epoch 194/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7790 - val_loss: 0.4649 - val_accuracy: 0.7626\n",
            "Epoch 195/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7772 - val_loss: 0.4672 - val_accuracy: 0.7626\n",
            "Epoch 196/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7790 - val_loss: 0.4677 - val_accuracy: 0.7626\n",
            "Epoch 197/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7826 - val_loss: 0.4606 - val_accuracy: 0.7698\n",
            "Epoch 198/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7862 - val_loss: 0.4662 - val_accuracy: 0.7626\n",
            "Epoch 199/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7844 - val_loss: 0.4644 - val_accuracy: 0.7626\n",
            "Epoch 200/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7790 - val_loss: 0.4698 - val_accuracy: 0.7626\n",
            "Epoch 201/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7826 - val_loss: 0.4692 - val_accuracy: 0.7626\n",
            "Epoch 202/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7880 - val_loss: 0.4679 - val_accuracy: 0.7626\n",
            "Epoch 203/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7826 - val_loss: 0.4712 - val_accuracy: 0.7626\n",
            "Epoch 204/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7826 - val_loss: 0.4689 - val_accuracy: 0.7626\n",
            "Epoch 205/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7844 - val_loss: 0.4694 - val_accuracy: 0.7626\n",
            "Epoch 206/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7826 - val_loss: 0.4622 - val_accuracy: 0.7698\n",
            "Epoch 207/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7808 - val_loss: 0.4646 - val_accuracy: 0.7626\n",
            "Epoch 208/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7790 - val_loss: 0.4647 - val_accuracy: 0.7626\n",
            "Epoch 209/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7736 - val_loss: 0.4722 - val_accuracy: 0.7554\n",
            "Epoch 210/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7772 - val_loss: 0.4644 - val_accuracy: 0.7626\n",
            "Epoch 211/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7826 - val_loss: 0.4640 - val_accuracy: 0.7626\n",
            "Epoch 212/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7844 - val_loss: 0.4774 - val_accuracy: 0.7554\n",
            "Epoch 213/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7808 - val_loss: 0.4741 - val_accuracy: 0.7554\n",
            "Epoch 214/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7808 - val_loss: 0.4727 - val_accuracy: 0.7554\n",
            "Epoch 215/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7826 - val_loss: 0.4692 - val_accuracy: 0.7626\n",
            "Epoch 216/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7772 - val_loss: 0.4705 - val_accuracy: 0.7626\n",
            "Epoch 217/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7790 - val_loss: 0.4661 - val_accuracy: 0.7626\n",
            "Epoch 218/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7826 - val_loss: 0.4674 - val_accuracy: 0.7626\n",
            "Epoch 219/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7808 - val_loss: 0.4621 - val_accuracy: 0.7626\n",
            "Epoch 220/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7790 - val_loss: 0.4656 - val_accuracy: 0.7626\n",
            "Epoch 221/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7790 - val_loss: 0.4641 - val_accuracy: 0.7626\n",
            "Epoch 222/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7862 - val_loss: 0.4640 - val_accuracy: 0.7626\n",
            "Epoch 223/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7826 - val_loss: 0.4686 - val_accuracy: 0.7626\n",
            "Epoch 224/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7844 - val_loss: 0.4701 - val_accuracy: 0.7626\n",
            "Epoch 225/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7826 - val_loss: 0.4735 - val_accuracy: 0.7554\n",
            "Epoch 226/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7790 - val_loss: 0.4674 - val_accuracy: 0.7626\n",
            "Epoch 227/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7790 - val_loss: 0.4642 - val_accuracy: 0.7626\n",
            "Epoch 228/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7772 - val_loss: 0.4682 - val_accuracy: 0.7626\n",
            "Epoch 229/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7808 - val_loss: 0.4710 - val_accuracy: 0.7554\n",
            "Epoch 230/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7808 - val_loss: 0.4677 - val_accuracy: 0.7626\n",
            "Epoch 231/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7844 - val_loss: 0.4656 - val_accuracy: 0.7626\n",
            "Epoch 232/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7808 - val_loss: 0.4616 - val_accuracy: 0.7626\n",
            "Epoch 233/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7808 - val_loss: 0.4615 - val_accuracy: 0.7626\n",
            "Epoch 234/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7844 - val_loss: 0.4624 - val_accuracy: 0.7626\n",
            "Epoch 235/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7862 - val_loss: 0.4670 - val_accuracy: 0.7626\n",
            "Epoch 236/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7790 - val_loss: 0.4561 - val_accuracy: 0.7986\n",
            "Epoch 237/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4683 - val_accuracy: 0.7626\n",
            "Epoch 238/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7826 - val_loss: 0.4639 - val_accuracy: 0.7626\n",
            "Epoch 239/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7790 - val_loss: 0.4552 - val_accuracy: 0.7986\n",
            "Epoch 240/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7862 - val_loss: 0.4691 - val_accuracy: 0.7626\n",
            "Epoch 241/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7862 - val_loss: 0.4637 - val_accuracy: 0.7626\n",
            "Epoch 242/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7844 - val_loss: 0.4631 - val_accuracy: 0.7626\n",
            "Epoch 243/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7826 - val_loss: 0.4631 - val_accuracy: 0.7626\n",
            "Epoch 244/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7844 - val_loss: 0.4541 - val_accuracy: 0.7914\n",
            "Epoch 245/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7880 - val_loss: 0.4654 - val_accuracy: 0.7626\n",
            "Epoch 246/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7880 - val_loss: 0.4595 - val_accuracy: 0.7698\n",
            "Epoch 247/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7790 - val_loss: 0.4609 - val_accuracy: 0.7626\n",
            "Epoch 248/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7844 - val_loss: 0.4678 - val_accuracy: 0.7626\n",
            "Epoch 249/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7844 - val_loss: 0.4603 - val_accuracy: 0.7626\n",
            "Epoch 250/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7844 - val_loss: 0.4696 - val_accuracy: 0.7554\n",
            "Epoch 251/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7844 - val_loss: 0.4640 - val_accuracy: 0.7626\n",
            "Epoch 252/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7844 - val_loss: 0.4710 - val_accuracy: 0.7554\n",
            "Epoch 253/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7844 - val_loss: 0.4658 - val_accuracy: 0.7626\n",
            "Epoch 254/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7880 - val_loss: 0.4763 - val_accuracy: 0.7554\n",
            "Epoch 255/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7808 - val_loss: 0.4683 - val_accuracy: 0.7626\n",
            "Epoch 256/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7826 - val_loss: 0.4665 - val_accuracy: 0.7626\n",
            "Epoch 257/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7844 - val_loss: 0.4696 - val_accuracy: 0.7554\n",
            "Epoch 258/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7844 - val_loss: 0.4729 - val_accuracy: 0.7554\n",
            "Epoch 259/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7862 - val_loss: 0.4633 - val_accuracy: 0.7626\n",
            "Epoch 260/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7844 - val_loss: 0.4669 - val_accuracy: 0.7626\n",
            "Epoch 261/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7844 - val_loss: 0.4625 - val_accuracy: 0.7626\n",
            "Epoch 262/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7862 - val_loss: 0.4625 - val_accuracy: 0.7626\n",
            "Epoch 263/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7808 - val_loss: 0.4666 - val_accuracy: 0.7626\n",
            "Epoch 264/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7826 - val_loss: 0.4689 - val_accuracy: 0.7554\n",
            "Epoch 265/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7862 - val_loss: 0.4678 - val_accuracy: 0.7626\n",
            "Epoch 266/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7844 - val_loss: 0.4671 - val_accuracy: 0.7626\n",
            "Epoch 267/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7790 - val_loss: 0.4634 - val_accuracy: 0.7698\n",
            "Epoch 268/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7808 - val_loss: 0.4605 - val_accuracy: 0.7626\n",
            "Epoch 269/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7880 - val_loss: 0.4626 - val_accuracy: 0.7626\n",
            "Epoch 270/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7862 - val_loss: 0.4737 - val_accuracy: 0.7554\n",
            "Epoch 271/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7880 - val_loss: 0.4714 - val_accuracy: 0.7554\n",
            "Epoch 272/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7862 - val_loss: 0.4702 - val_accuracy: 0.7554\n",
            "Epoch 273/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7844 - val_loss: 0.4680 - val_accuracy: 0.7554\n",
            "Epoch 274/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7790 - val_loss: 0.4697 - val_accuracy: 0.7554\n",
            "Epoch 275/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7862 - val_loss: 0.4626 - val_accuracy: 0.7626\n",
            "Epoch 276/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7880 - val_loss: 0.4645 - val_accuracy: 0.7626\n",
            "Epoch 277/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7899 - val_loss: 0.4682 - val_accuracy: 0.7554\n",
            "Epoch 278/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7844 - val_loss: 0.4634 - val_accuracy: 0.7626\n",
            "Epoch 279/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7862 - val_loss: 0.4623 - val_accuracy: 0.7626\n",
            "Epoch 280/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7862 - val_loss: 0.4635 - val_accuracy: 0.7626\n",
            "Epoch 281/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7862 - val_loss: 0.4661 - val_accuracy: 0.7626\n",
            "Epoch 282/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7880 - val_loss: 0.4624 - val_accuracy: 0.7626\n",
            "Epoch 283/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4832 - val_accuracy: 0.7554\n",
            "Epoch 284/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7808 - val_loss: 0.4722 - val_accuracy: 0.7554\n",
            "Epoch 285/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7808 - val_loss: 0.4641 - val_accuracy: 0.7626\n",
            "Epoch 286/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7862 - val_loss: 0.4653 - val_accuracy: 0.7626\n",
            "Epoch 287/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7808 - val_loss: 0.4595 - val_accuracy: 0.7626\n",
            "Epoch 288/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7862 - val_loss: 0.4654 - val_accuracy: 0.7626\n",
            "Epoch 289/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7862 - val_loss: 0.4617 - val_accuracy: 0.7626\n",
            "Epoch 290/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7899 - val_loss: 0.4655 - val_accuracy: 0.7626\n",
            "Epoch 291/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7880 - val_loss: 0.4667 - val_accuracy: 0.7554\n",
            "Epoch 292/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7917 - val_loss: 0.4723 - val_accuracy: 0.7554\n",
            "Epoch 293/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7862 - val_loss: 0.4614 - val_accuracy: 0.7626\n",
            "Epoch 294/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7971 - val_loss: 0.4675 - val_accuracy: 0.7554\n",
            "Epoch 295/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7862 - val_loss: 0.4670 - val_accuracy: 0.7554\n",
            "Epoch 296/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7844 - val_loss: 0.4615 - val_accuracy: 0.7698\n",
            "Epoch 297/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7880 - val_loss: 0.4610 - val_accuracy: 0.7626\n",
            "Epoch 298/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7880 - val_loss: 0.4656 - val_accuracy: 0.7554\n",
            "Epoch 299/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7953 - val_loss: 0.4705 - val_accuracy: 0.7554\n",
            "Epoch 300/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7880 - val_loss: 0.4661 - val_accuracy: 0.7554\n",
            "Epoch 301/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7844 - val_loss: 0.4694 - val_accuracy: 0.7554\n",
            "Epoch 302/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7880 - val_loss: 0.4687 - val_accuracy: 0.7554\n",
            "Epoch 303/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4718 - val_accuracy: 0.7554\n",
            "Epoch 304/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7808 - val_loss: 0.4712 - val_accuracy: 0.7554\n",
            "Epoch 305/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7844 - val_loss: 0.4635 - val_accuracy: 0.7626\n",
            "Epoch 306/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7935 - val_loss: 0.4672 - val_accuracy: 0.7554\n",
            "Epoch 307/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7880 - val_loss: 0.4642 - val_accuracy: 0.7626\n",
            "Epoch 308/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7935 - val_loss: 0.4627 - val_accuracy: 0.7626\n",
            "Epoch 309/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7917 - val_loss: 0.4674 - val_accuracy: 0.7554\n",
            "Epoch 310/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7826 - val_loss: 0.4578 - val_accuracy: 0.7698\n",
            "Epoch 311/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.4586 - val_accuracy: 0.7770\n",
            "Epoch 312/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7844 - val_loss: 0.4620 - val_accuracy: 0.7626\n",
            "Epoch 313/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7844 - val_loss: 0.4574 - val_accuracy: 0.7770\n",
            "Epoch 314/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7880 - val_loss: 0.4666 - val_accuracy: 0.7554\n",
            "Epoch 315/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7862 - val_loss: 0.4581 - val_accuracy: 0.7770\n",
            "Epoch 316/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7880 - val_loss: 0.4674 - val_accuracy: 0.7554\n",
            "Epoch 317/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7844 - val_loss: 0.4579 - val_accuracy: 0.7770\n",
            "Epoch 318/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7917 - val_loss: 0.4635 - val_accuracy: 0.7626\n",
            "Epoch 319/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.4635 - val_accuracy: 0.7626\n",
            "Epoch 320/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7844 - val_loss: 0.4710 - val_accuracy: 0.7554\n",
            "Epoch 321/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7935 - val_loss: 0.4595 - val_accuracy: 0.7626\n",
            "Epoch 322/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7844 - val_loss: 0.4678 - val_accuracy: 0.7554\n",
            "Epoch 323/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7935 - val_loss: 0.4660 - val_accuracy: 0.7554\n",
            "Epoch 324/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4638 - val_accuracy: 0.7626\n",
            "Epoch 325/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7844 - val_loss: 0.4665 - val_accuracy: 0.7554\n",
            "Epoch 326/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4585 - val_accuracy: 0.7698\n",
            "Epoch 327/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7917 - val_loss: 0.4627 - val_accuracy: 0.7626\n",
            "Epoch 328/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4607 - val_accuracy: 0.7626\n",
            "Epoch 329/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7880 - val_loss: 0.4551 - val_accuracy: 0.7842\n",
            "Epoch 330/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7826 - val_loss: 0.4604 - val_accuracy: 0.7626\n",
            "Epoch 331/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7826 - val_loss: 0.4628 - val_accuracy: 0.7626\n",
            "Epoch 332/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4637 - val_accuracy: 0.7554\n",
            "Epoch 333/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7862 - val_loss: 0.4618 - val_accuracy: 0.7626\n",
            "Epoch 334/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4627 - val_accuracy: 0.7626\n",
            "Epoch 335/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4664 - val_accuracy: 0.7554\n",
            "Epoch 336/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7844 - val_loss: 0.4545 - val_accuracy: 0.7842\n",
            "Epoch 337/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7790 - val_loss: 0.4658 - val_accuracy: 0.7554\n",
            "Epoch 338/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7826 - val_loss: 0.4527 - val_accuracy: 0.7914\n",
            "Epoch 339/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7808 - val_loss: 0.4655 - val_accuracy: 0.7554\n",
            "Epoch 340/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4633 - val_accuracy: 0.7554\n",
            "Epoch 341/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7880 - val_loss: 0.4574 - val_accuracy: 0.7842\n",
            "Epoch 342/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7826 - val_loss: 0.4630 - val_accuracy: 0.7554\n",
            "Epoch 343/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7880 - val_loss: 0.4600 - val_accuracy: 0.7626\n",
            "Epoch 344/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4631 - val_accuracy: 0.7554\n",
            "Epoch 345/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4612 - val_accuracy: 0.7626\n",
            "Epoch 346/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7880 - val_loss: 0.4589 - val_accuracy: 0.7698\n",
            "Epoch 347/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7826 - val_loss: 0.4602 - val_accuracy: 0.7626\n",
            "Epoch 348/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7862 - val_loss: 0.4723 - val_accuracy: 0.7554\n",
            "Epoch 349/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7844 - val_loss: 0.4600 - val_accuracy: 0.7626\n",
            "Epoch 350/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7880 - val_loss: 0.4698 - val_accuracy: 0.7554\n",
            "Epoch 351/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4596 - val_accuracy: 0.7626\n",
            "Epoch 352/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.4561 - val_accuracy: 0.7842\n",
            "Epoch 353/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7844 - val_loss: 0.4664 - val_accuracy: 0.7554\n",
            "Epoch 354/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7880 - val_loss: 0.4680 - val_accuracy: 0.7554\n",
            "Epoch 355/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7808 - val_loss: 0.4597 - val_accuracy: 0.7626\n",
            "Epoch 356/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4656 - val_accuracy: 0.7554\n",
            "Epoch 357/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7826 - val_loss: 0.4647 - val_accuracy: 0.7554\n",
            "Epoch 358/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4622 - val_accuracy: 0.7554\n",
            "Epoch 359/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7862 - val_loss: 0.4631 - val_accuracy: 0.7554\n",
            "Epoch 360/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7862 - val_loss: 0.4603 - val_accuracy: 0.7626\n",
            "Epoch 361/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4655 - val_accuracy: 0.7554\n",
            "Epoch 362/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7808 - val_loss: 0.4642 - val_accuracy: 0.7554\n",
            "Epoch 363/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4572 - val_accuracy: 0.7842\n",
            "Epoch 364/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7862 - val_loss: 0.4539 - val_accuracy: 0.7914\n",
            "Epoch 365/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7844 - val_loss: 0.4670 - val_accuracy: 0.7554\n",
            "Epoch 366/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7844 - val_loss: 0.4707 - val_accuracy: 0.7554\n",
            "Epoch 367/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7826 - val_loss: 0.4590 - val_accuracy: 0.7698\n",
            "Epoch 368/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.4591 - val_accuracy: 0.7698\n",
            "Epoch 369/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7862 - val_loss: 0.4615 - val_accuracy: 0.7554\n",
            "Epoch 370/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7826 - val_loss: 0.4583 - val_accuracy: 0.7698\n",
            "Epoch 371/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7844 - val_loss: 0.4580 - val_accuracy: 0.7770\n",
            "Epoch 372/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4675 - val_accuracy: 0.7554\n",
            "Epoch 373/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7880 - val_loss: 0.4663 - val_accuracy: 0.7554\n",
            "Epoch 374/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7844 - val_loss: 0.4609 - val_accuracy: 0.7554\n",
            "Epoch 375/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7862 - val_loss: 0.4619 - val_accuracy: 0.7554\n",
            "Epoch 376/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7880 - val_loss: 0.4552 - val_accuracy: 0.7914\n",
            "Epoch 377/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4568 - val_accuracy: 0.7914\n",
            "Epoch 378/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7880 - val_loss: 0.4554 - val_accuracy: 0.7914\n",
            "Epoch 379/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7880 - val_loss: 0.4677 - val_accuracy: 0.7554\n",
            "Epoch 380/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7880 - val_loss: 0.4616 - val_accuracy: 0.7554\n",
            "Epoch 381/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7826 - val_loss: 0.4614 - val_accuracy: 0.7554\n",
            "Epoch 382/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7808 - val_loss: 0.4689 - val_accuracy: 0.7554\n",
            "Epoch 383/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7880 - val_loss: 0.4610 - val_accuracy: 0.7554\n",
            "Epoch 384/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4624 - val_accuracy: 0.7554\n",
            "Epoch 385/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7880 - val_loss: 0.4625 - val_accuracy: 0.7554\n",
            "Epoch 386/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7862 - val_loss: 0.4602 - val_accuracy: 0.7626\n",
            "Epoch 387/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7844 - val_loss: 0.4608 - val_accuracy: 0.7554\n",
            "Epoch 388/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7862 - val_loss: 0.4699 - val_accuracy: 0.7554\n",
            "Epoch 389/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7862 - val_loss: 0.4686 - val_accuracy: 0.7554\n",
            "Epoch 390/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7917 - val_loss: 0.4622 - val_accuracy: 0.7554\n",
            "Epoch 391/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7844 - val_loss: 0.4538 - val_accuracy: 0.7914\n",
            "Epoch 392/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7862 - val_loss: 0.4615 - val_accuracy: 0.7554\n",
            "Epoch 393/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7826 - val_loss: 0.4582 - val_accuracy: 0.7698\n",
            "Epoch 394/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7790 - val_loss: 0.4583 - val_accuracy: 0.7770\n",
            "Epoch 395/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7844 - val_loss: 0.4612 - val_accuracy: 0.7626\n",
            "Epoch 396/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7880 - val_loss: 0.4580 - val_accuracy: 0.7770\n",
            "Epoch 397/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4683 - val_accuracy: 0.7554\n",
            "Epoch 398/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7862 - val_loss: 0.4751 - val_accuracy: 0.7554\n",
            "Epoch 399/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4659 - val_accuracy: 0.7554\n",
            "Epoch 400/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7880 - val_loss: 0.4677 - val_accuracy: 0.7554\n",
            "Epoch 401/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7826 - val_loss: 0.4614 - val_accuracy: 0.7626\n",
            "Epoch 402/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7880 - val_loss: 0.4635 - val_accuracy: 0.7626\n",
            "Epoch 403/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4611 - val_accuracy: 0.7626\n",
            "Epoch 404/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7844 - val_loss: 0.4616 - val_accuracy: 0.7626\n",
            "Epoch 405/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7826 - val_loss: 0.4720 - val_accuracy: 0.7554\n",
            "Epoch 406/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7880 - val_loss: 0.4731 - val_accuracy: 0.7554\n",
            "Epoch 407/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7880 - val_loss: 0.4598 - val_accuracy: 0.7626\n",
            "Epoch 408/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7862 - val_loss: 0.4566 - val_accuracy: 0.7842\n",
            "Epoch 409/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7808 - val_loss: 0.4557 - val_accuracy: 0.7842\n",
            "Epoch 410/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7880 - val_loss: 0.4627 - val_accuracy: 0.7626\n",
            "Epoch 411/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7880 - val_loss: 0.4568 - val_accuracy: 0.7770\n",
            "Epoch 412/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7880 - val_loss: 0.4611 - val_accuracy: 0.7626\n",
            "Epoch 413/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7917 - val_loss: 0.4630 - val_accuracy: 0.7626\n",
            "Epoch 414/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7826 - val_loss: 0.4584 - val_accuracy: 0.7770\n",
            "Epoch 415/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7862 - val_loss: 0.4661 - val_accuracy: 0.7626\n",
            "Epoch 416/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7844 - val_loss: 0.4717 - val_accuracy: 0.7554\n",
            "Epoch 417/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.4617 - val_accuracy: 0.7626\n",
            "Epoch 418/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7808 - val_loss: 0.4620 - val_accuracy: 0.7626\n",
            "Epoch 419/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7808 - val_loss: 0.4667 - val_accuracy: 0.7626\n",
            "Epoch 420/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7808 - val_loss: 0.4649 - val_accuracy: 0.7626\n",
            "Epoch 421/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7808 - val_loss: 0.4632 - val_accuracy: 0.7626\n",
            "Epoch 422/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7862 - val_loss: 0.4528 - val_accuracy: 0.7914\n",
            "Epoch 423/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7826 - val_loss: 0.4676 - val_accuracy: 0.7626\n",
            "Epoch 424/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7790 - val_loss: 0.4702 - val_accuracy: 0.7626\n",
            "Epoch 425/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7862 - val_loss: 0.4643 - val_accuracy: 0.7626\n",
            "Epoch 426/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7862 - val_loss: 0.4630 - val_accuracy: 0.7626\n",
            "Epoch 427/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7826 - val_loss: 0.4676 - val_accuracy: 0.7626\n",
            "Epoch 428/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7880 - val_loss: 0.4569 - val_accuracy: 0.7770\n",
            "Epoch 429/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7880 - val_loss: 0.4652 - val_accuracy: 0.7626\n",
            "Epoch 430/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7844 - val_loss: 0.4592 - val_accuracy: 0.7698\n",
            "Epoch 431/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7808 - val_loss: 0.4603 - val_accuracy: 0.7626\n",
            "Epoch 432/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7790 - val_loss: 0.4714 - val_accuracy: 0.7626\n",
            "Epoch 433/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7880 - val_loss: 0.4687 - val_accuracy: 0.7626\n",
            "Epoch 434/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7844 - val_loss: 0.4706 - val_accuracy: 0.7626\n",
            "Epoch 435/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7844 - val_loss: 0.4579 - val_accuracy: 0.7698\n",
            "Epoch 436/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7862 - val_loss: 0.4611 - val_accuracy: 0.7626\n",
            "Epoch 437/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7880 - val_loss: 0.4583 - val_accuracy: 0.7698\n",
            "Epoch 438/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7880 - val_loss: 0.4637 - val_accuracy: 0.7626\n",
            "Epoch 439/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4555 - val_accuracy: 0.7770\n",
            "Epoch 440/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7808 - val_loss: 0.4662 - val_accuracy: 0.7626\n",
            "Epoch 441/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7844 - val_loss: 0.4544 - val_accuracy: 0.7914\n",
            "Epoch 442/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4633 - val_accuracy: 0.7626\n",
            "Epoch 443/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7844 - val_loss: 0.4682 - val_accuracy: 0.7626\n",
            "Epoch 444/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7826 - val_loss: 0.4664 - val_accuracy: 0.7626\n",
            "Epoch 445/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7880 - val_loss: 0.4645 - val_accuracy: 0.7626\n",
            "Epoch 446/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7826 - val_loss: 0.4622 - val_accuracy: 0.7626\n",
            "Epoch 447/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7862 - val_loss: 0.4571 - val_accuracy: 0.7698\n",
            "Epoch 448/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7790 - val_loss: 0.4538 - val_accuracy: 0.7842\n",
            "Epoch 449/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7862 - val_loss: 0.4578 - val_accuracy: 0.7698\n",
            "Epoch 450/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7772 - val_loss: 0.4673 - val_accuracy: 0.7626\n",
            "Epoch 451/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4564 - val_accuracy: 0.7770\n",
            "Epoch 452/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7862 - val_loss: 0.4579 - val_accuracy: 0.7698\n",
            "Epoch 453/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7826 - val_loss: 0.4546 - val_accuracy: 0.7770\n",
            "Epoch 454/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7844 - val_loss: 0.4586 - val_accuracy: 0.7698\n",
            "Epoch 455/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7862 - val_loss: 0.4589 - val_accuracy: 0.7698\n",
            "Epoch 456/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7844 - val_loss: 0.4588 - val_accuracy: 0.7626\n",
            "Epoch 457/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7935 - val_loss: 0.4564 - val_accuracy: 0.7698\n",
            "Epoch 458/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7790 - val_loss: 0.4740 - val_accuracy: 0.7626\n",
            "Epoch 459/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7844 - val_loss: 0.4661 - val_accuracy: 0.7626\n",
            "Epoch 460/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7808 - val_loss: 0.4570 - val_accuracy: 0.7698\n",
            "Epoch 461/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4599 - val_accuracy: 0.7626\n",
            "Epoch 462/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7844 - val_loss: 0.4613 - val_accuracy: 0.7626\n",
            "Epoch 463/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7826 - val_loss: 0.4618 - val_accuracy: 0.7626\n",
            "Epoch 464/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7808 - val_loss: 0.4619 - val_accuracy: 0.7626\n",
            "Epoch 465/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7844 - val_loss: 0.4610 - val_accuracy: 0.7626\n",
            "Epoch 466/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7862 - val_loss: 0.4669 - val_accuracy: 0.7626\n",
            "Epoch 467/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7826 - val_loss: 0.4604 - val_accuracy: 0.7626\n",
            "Epoch 468/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7844 - val_loss: 0.4572 - val_accuracy: 0.7698\n",
            "Epoch 469/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7844 - val_loss: 0.4655 - val_accuracy: 0.7626\n",
            "Epoch 470/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7862 - val_loss: 0.4623 - val_accuracy: 0.7626\n",
            "Epoch 471/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7880 - val_loss: 0.4663 - val_accuracy: 0.7626\n",
            "Epoch 472/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7862 - val_loss: 0.4678 - val_accuracy: 0.7626\n",
            "Epoch 473/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4610 - val_accuracy: 0.7626\n",
            "Epoch 474/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7844 - val_loss: 0.4600 - val_accuracy: 0.7626\n",
            "Epoch 475/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7880 - val_loss: 0.4573 - val_accuracy: 0.7698\n",
            "Epoch 476/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7862 - val_loss: 0.4626 - val_accuracy: 0.7626\n",
            "Epoch 477/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7844 - val_loss: 0.4611 - val_accuracy: 0.7626\n",
            "Epoch 478/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7844 - val_loss: 0.4613 - val_accuracy: 0.7626\n",
            "Epoch 479/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7790 - val_loss: 0.4574 - val_accuracy: 0.7698\n",
            "Epoch 480/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7826 - val_loss: 0.4646 - val_accuracy: 0.7626\n",
            "Epoch 481/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7844 - val_loss: 0.4578 - val_accuracy: 0.7698\n",
            "Epoch 482/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7772 - val_loss: 0.4540 - val_accuracy: 0.7770\n",
            "Epoch 483/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7808 - val_loss: 0.4591 - val_accuracy: 0.7698\n",
            "Epoch 484/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7862 - val_loss: 0.4697 - val_accuracy: 0.7626\n",
            "Epoch 485/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7844 - val_loss: 0.4609 - val_accuracy: 0.7626\n",
            "Epoch 486/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7862 - val_loss: 0.4593 - val_accuracy: 0.7698\n",
            "Epoch 487/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7826 - val_loss: 0.4598 - val_accuracy: 0.7698\n",
            "Epoch 488/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7862 - val_loss: 0.4547 - val_accuracy: 0.7698\n",
            "Epoch 489/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7826 - val_loss: 0.4560 - val_accuracy: 0.7698\n",
            "Epoch 490/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7826 - val_loss: 0.4596 - val_accuracy: 0.7698\n",
            "Epoch 491/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7844 - val_loss: 0.4544 - val_accuracy: 0.7698\n",
            "Epoch 492/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7880 - val_loss: 0.4750 - val_accuracy: 0.7626\n",
            "Epoch 493/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7862 - val_loss: 0.4731 - val_accuracy: 0.7626\n",
            "Epoch 494/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7862 - val_loss: 0.4563 - val_accuracy: 0.7698\n",
            "Epoch 495/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7844 - val_loss: 0.4577 - val_accuracy: 0.7698\n",
            "Epoch 496/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7808 - val_loss: 0.4558 - val_accuracy: 0.7698\n",
            "Epoch 497/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7862 - val_loss: 0.4577 - val_accuracy: 0.7698\n",
            "Epoch 498/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7808 - val_loss: 0.4609 - val_accuracy: 0.7626\n",
            "Epoch 499/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7844 - val_loss: 0.4544 - val_accuracy: 0.7698\n",
            "Epoch 500/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7844 - val_loss: 0.4572 - val_accuracy: 0.7698\n",
            "Epoch 501/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.4559 - val_accuracy: 0.7698\n",
            "Epoch 502/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7790 - val_loss: 0.4631 - val_accuracy: 0.7626\n",
            "Epoch 503/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7808 - val_loss: 0.4574 - val_accuracy: 0.7698\n",
            "Epoch 504/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7862 - val_loss: 0.4546 - val_accuracy: 0.7698\n",
            "Epoch 505/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7826 - val_loss: 0.4556 - val_accuracy: 0.7698\n",
            "Epoch 506/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7880 - val_loss: 0.4560 - val_accuracy: 0.7698\n",
            "Epoch 507/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7862 - val_loss: 0.4541 - val_accuracy: 0.7698\n",
            "Epoch 508/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7826 - val_loss: 0.4531 - val_accuracy: 0.7770\n",
            "Epoch 509/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7808 - val_loss: 0.4615 - val_accuracy: 0.7626\n",
            "Epoch 510/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7844 - val_loss: 0.4661 - val_accuracy: 0.7626\n",
            "Epoch 511/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7844 - val_loss: 0.4579 - val_accuracy: 0.7698\n",
            "Epoch 512/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7862 - val_loss: 0.4616 - val_accuracy: 0.7626\n",
            "Epoch 513/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7826 - val_loss: 0.4602 - val_accuracy: 0.7698\n",
            "Epoch 514/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7808 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 515/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7790 - val_loss: 0.4607 - val_accuracy: 0.7698\n",
            "Epoch 516/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7844 - val_loss: 0.4525 - val_accuracy: 0.7770\n",
            "Epoch 517/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7844 - val_loss: 0.4577 - val_accuracy: 0.7698\n",
            "Epoch 518/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7826 - val_loss: 0.4623 - val_accuracy: 0.7626\n",
            "Epoch 519/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7844 - val_loss: 0.4590 - val_accuracy: 0.7698\n",
            "Epoch 520/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7790 - val_loss: 0.4461 - val_accuracy: 0.7914\n",
            "Epoch 521/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7826 - val_loss: 0.4624 - val_accuracy: 0.7626\n",
            "Epoch 522/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7808 - val_loss: 0.4509 - val_accuracy: 0.7770\n",
            "Epoch 523/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7826 - val_loss: 0.4537 - val_accuracy: 0.7698\n",
            "Epoch 524/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7790 - val_loss: 0.4609 - val_accuracy: 0.7698\n",
            "Epoch 525/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7826 - val_loss: 0.4572 - val_accuracy: 0.7698\n",
            "Epoch 526/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7826 - val_loss: 0.4597 - val_accuracy: 0.7698\n",
            "Epoch 527/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7826 - val_loss: 0.4610 - val_accuracy: 0.7698\n",
            "Epoch 528/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7808 - val_loss: 0.4570 - val_accuracy: 0.7698\n",
            "Epoch 529/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7826 - val_loss: 0.4556 - val_accuracy: 0.7698\n",
            "Epoch 530/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7826 - val_loss: 0.4540 - val_accuracy: 0.7698\n",
            "Epoch 531/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7790 - val_loss: 0.4595 - val_accuracy: 0.7698\n",
            "Epoch 532/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7862 - val_loss: 0.4534 - val_accuracy: 0.7698\n",
            "Epoch 533/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7844 - val_loss: 0.4609 - val_accuracy: 0.7698\n",
            "Epoch 534/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7880 - val_loss: 0.4603 - val_accuracy: 0.7698\n",
            "Epoch 535/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7862 - val_loss: 0.4560 - val_accuracy: 0.7698\n",
            "Epoch 536/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7862 - val_loss: 0.4599 - val_accuracy: 0.7698\n",
            "Epoch 537/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7808 - val_loss: 0.4574 - val_accuracy: 0.7698\n",
            "Epoch 538/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7826 - val_loss: 0.4573 - val_accuracy: 0.7698\n",
            "Epoch 539/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7826 - val_loss: 0.4637 - val_accuracy: 0.7626\n",
            "Epoch 540/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7808 - val_loss: 0.4647 - val_accuracy: 0.7626\n",
            "Epoch 541/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7844 - val_loss: 0.4573 - val_accuracy: 0.7698\n",
            "Epoch 542/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7826 - val_loss: 0.4655 - val_accuracy: 0.7626\n",
            "Epoch 543/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7880 - val_loss: 0.4477 - val_accuracy: 0.7914\n",
            "Epoch 544/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7772 - val_loss: 0.4460 - val_accuracy: 0.7914\n",
            "Epoch 545/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7790 - val_loss: 0.4516 - val_accuracy: 0.7698\n",
            "Epoch 546/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7826 - val_loss: 0.4591 - val_accuracy: 0.7698\n",
            "Epoch 547/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7844 - val_loss: 0.4658 - val_accuracy: 0.7626\n",
            "Epoch 548/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7808 - val_loss: 0.4652 - val_accuracy: 0.7626\n",
            "Epoch 549/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7844 - val_loss: 0.4617 - val_accuracy: 0.7698\n",
            "Epoch 550/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7826 - val_loss: 0.4575 - val_accuracy: 0.7698\n",
            "Epoch 551/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7826 - val_loss: 0.4528 - val_accuracy: 0.7698\n",
            "Epoch 552/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7826 - val_loss: 0.4554 - val_accuracy: 0.7698\n",
            "Epoch 553/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7862 - val_loss: 0.4525 - val_accuracy: 0.7698\n",
            "Epoch 554/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7844 - val_loss: 0.4580 - val_accuracy: 0.7698\n",
            "Epoch 555/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7826 - val_loss: 0.4566 - val_accuracy: 0.7698\n",
            "Epoch 556/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7826 - val_loss: 0.4582 - val_accuracy: 0.7698\n",
            "Epoch 557/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7826 - val_loss: 0.4507 - val_accuracy: 0.7770\n",
            "Epoch 558/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7862 - val_loss: 0.4607 - val_accuracy: 0.7698\n",
            "Epoch 559/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7808 - val_loss: 0.4593 - val_accuracy: 0.7698\n",
            "Epoch 560/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7862 - val_loss: 0.4687 - val_accuracy: 0.7626\n",
            "Epoch 561/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7826 - val_loss: 0.4601 - val_accuracy: 0.7698\n",
            "Epoch 562/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7826 - val_loss: 0.4601 - val_accuracy: 0.7698\n",
            "Epoch 563/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7880 - val_loss: 0.4589 - val_accuracy: 0.7698\n",
            "Epoch 564/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7772 - val_loss: 0.4509 - val_accuracy: 0.7770\n",
            "Epoch 565/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7790 - val_loss: 0.4594 - val_accuracy: 0.7698\n",
            "Epoch 566/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7826 - val_loss: 0.4596 - val_accuracy: 0.7698\n",
            "Epoch 567/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7808 - val_loss: 0.4531 - val_accuracy: 0.7698\n",
            "Epoch 568/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7808 - val_loss: 0.4569 - val_accuracy: 0.7698\n",
            "Epoch 569/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7862 - val_loss: 0.4589 - val_accuracy: 0.7698\n",
            "Epoch 570/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7844 - val_loss: 0.4482 - val_accuracy: 0.7986\n",
            "Epoch 571/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7880 - val_loss: 0.4640 - val_accuracy: 0.7626\n",
            "Epoch 572/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.4624 - val_accuracy: 0.7626\n",
            "Epoch 573/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7808 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 574/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7808 - val_loss: 0.4583 - val_accuracy: 0.7698\n",
            "Epoch 575/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7880 - val_loss: 0.4529 - val_accuracy: 0.7698\n",
            "Epoch 576/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7844 - val_loss: 0.4598 - val_accuracy: 0.7698\n",
            "Epoch 577/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7808 - val_loss: 0.4546 - val_accuracy: 0.7698\n",
            "Epoch 578/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7844 - val_loss: 0.4594 - val_accuracy: 0.7698\n",
            "Epoch 579/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7808 - val_loss: 0.4572 - val_accuracy: 0.7698\n",
            "Epoch 580/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7862 - val_loss: 0.4628 - val_accuracy: 0.7626\n",
            "Epoch 581/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7844 - val_loss: 0.4539 - val_accuracy: 0.7698\n",
            "Epoch 582/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7844 - val_loss: 0.4532 - val_accuracy: 0.7698\n",
            "Epoch 583/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7880 - val_loss: 0.4639 - val_accuracy: 0.7626\n",
            "Epoch 584/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7808 - val_loss: 0.4517 - val_accuracy: 0.7698\n",
            "Epoch 585/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7862 - val_loss: 0.4563 - val_accuracy: 0.7698\n",
            "Epoch 586/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7880 - val_loss: 0.4594 - val_accuracy: 0.7698\n",
            "Epoch 587/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7880 - val_loss: 0.4646 - val_accuracy: 0.7626\n",
            "Epoch 588/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7844 - val_loss: 0.4624 - val_accuracy: 0.7626\n",
            "Epoch 589/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7826 - val_loss: 0.4568 - val_accuracy: 0.7698\n",
            "Epoch 590/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7826 - val_loss: 0.4546 - val_accuracy: 0.7698\n",
            "Epoch 591/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7826 - val_loss: 0.4557 - val_accuracy: 0.7698\n",
            "Epoch 592/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7899 - val_loss: 0.4528 - val_accuracy: 0.7698\n",
            "Epoch 593/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7862 - val_loss: 0.4559 - val_accuracy: 0.7698\n",
            "Epoch 594/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7862 - val_loss: 0.4588 - val_accuracy: 0.7698\n",
            "Epoch 595/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7844 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 596/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7844 - val_loss: 0.4570 - val_accuracy: 0.7698\n",
            "Epoch 597/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7826 - val_loss: 0.4557 - val_accuracy: 0.7698\n",
            "Epoch 598/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7844 - val_loss: 0.4521 - val_accuracy: 0.7698\n",
            "Epoch 599/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7844 - val_loss: 0.4479 - val_accuracy: 0.7986\n",
            "Epoch 600/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7880 - val_loss: 0.4632 - val_accuracy: 0.7626\n",
            "Epoch 601/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7772 - val_loss: 0.4504 - val_accuracy: 0.7698\n",
            "Epoch 602/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7808 - val_loss: 0.4508 - val_accuracy: 0.7698\n",
            "Epoch 603/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7826 - val_loss: 0.4481 - val_accuracy: 0.7914\n",
            "Epoch 604/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7862 - val_loss: 0.4598 - val_accuracy: 0.7698\n",
            "Epoch 605/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7808 - val_loss: 0.4567 - val_accuracy: 0.7698\n",
            "Epoch 606/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7844 - val_loss: 0.4622 - val_accuracy: 0.7626\n",
            "Epoch 607/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7844 - val_loss: 0.4471 - val_accuracy: 0.7986\n",
            "Epoch 608/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7899 - val_loss: 0.4605 - val_accuracy: 0.7698\n",
            "Epoch 609/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7826 - val_loss: 0.4651 - val_accuracy: 0.7626\n",
            "Epoch 610/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7826 - val_loss: 0.4610 - val_accuracy: 0.7626\n",
            "Epoch 611/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7880 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 612/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7844 - val_loss: 0.4574 - val_accuracy: 0.7698\n",
            "Epoch 613/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7844 - val_loss: 0.4536 - val_accuracy: 0.7698\n",
            "Epoch 614/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7808 - val_loss: 0.4604 - val_accuracy: 0.7698\n",
            "Epoch 615/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7844 - val_loss: 0.4600 - val_accuracy: 0.7698\n",
            "Epoch 616/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7880 - val_loss: 0.4598 - val_accuracy: 0.7698\n",
            "Epoch 617/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7790 - val_loss: 0.4510 - val_accuracy: 0.7698\n",
            "Epoch 618/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7826 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 619/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7790 - val_loss: 0.4559 - val_accuracy: 0.7698\n",
            "Epoch 620/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7808 - val_loss: 0.4531 - val_accuracy: 0.7698\n",
            "Epoch 621/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7808 - val_loss: 0.4516 - val_accuracy: 0.7698\n",
            "Epoch 622/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7844 - val_loss: 0.4567 - val_accuracy: 0.7698\n",
            "Epoch 623/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7862 - val_loss: 0.4444 - val_accuracy: 0.7914\n",
            "Epoch 624/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7880 - val_loss: 0.4610 - val_accuracy: 0.7698\n",
            "Epoch 625/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7862 - val_loss: 0.4626 - val_accuracy: 0.7626\n",
            "Epoch 626/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7808 - val_loss: 0.4665 - val_accuracy: 0.7626\n",
            "Epoch 627/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7808 - val_loss: 0.4512 - val_accuracy: 0.7698\n",
            "Epoch 628/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7862 - val_loss: 0.4564 - val_accuracy: 0.7698\n",
            "Epoch 629/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7917 - val_loss: 0.4744 - val_accuracy: 0.7770\n",
            "Epoch 630/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7790 - val_loss: 0.4544 - val_accuracy: 0.7698\n",
            "Epoch 631/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7754 - val_loss: 0.4444 - val_accuracy: 0.7914\n",
            "Epoch 632/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7862 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 633/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7808 - val_loss: 0.4597 - val_accuracy: 0.7698\n",
            "Epoch 634/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7826 - val_loss: 0.4487 - val_accuracy: 0.7698\n",
            "Epoch 635/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7880 - val_loss: 0.4666 - val_accuracy: 0.7626\n",
            "Epoch 636/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7844 - val_loss: 0.4658 - val_accuracy: 0.7626\n",
            "Epoch 637/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7790 - val_loss: 0.4506 - val_accuracy: 0.7698\n",
            "Epoch 638/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7862 - val_loss: 0.4522 - val_accuracy: 0.7698\n",
            "Epoch 639/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7844 - val_loss: 0.4484 - val_accuracy: 0.7698\n",
            "Epoch 640/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7862 - val_loss: 0.4623 - val_accuracy: 0.7626\n",
            "Epoch 641/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7844 - val_loss: 0.4545 - val_accuracy: 0.7698\n",
            "Epoch 642/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7880 - val_loss: 0.4602 - val_accuracy: 0.7698\n",
            "Epoch 643/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7862 - val_loss: 0.4523 - val_accuracy: 0.7698\n",
            "Epoch 644/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7826 - val_loss: 0.4471 - val_accuracy: 0.7842\n",
            "Epoch 645/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7790 - val_loss: 0.4506 - val_accuracy: 0.7698\n",
            "Epoch 646/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7844 - val_loss: 0.4566 - val_accuracy: 0.7698\n",
            "Epoch 647/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7826 - val_loss: 0.4563 - val_accuracy: 0.7698\n",
            "Epoch 648/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7808 - val_loss: 0.4549 - val_accuracy: 0.7698\n",
            "Epoch 649/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7826 - val_loss: 0.4549 - val_accuracy: 0.7698\n",
            "Epoch 650/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7862 - val_loss: 0.4683 - val_accuracy: 0.7698\n",
            "Epoch 651/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7790 - val_loss: 0.4613 - val_accuracy: 0.7698\n",
            "Epoch 652/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7844 - val_loss: 0.4528 - val_accuracy: 0.7698\n",
            "Epoch 653/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7808 - val_loss: 0.4542 - val_accuracy: 0.7698\n",
            "Epoch 654/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7880 - val_loss: 0.4558 - val_accuracy: 0.7698\n",
            "Epoch 655/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.4452 - val_accuracy: 0.7986\n",
            "Epoch 656/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7826 - val_loss: 0.4535 - val_accuracy: 0.7698\n",
            "Epoch 657/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7880 - val_loss: 0.4479 - val_accuracy: 0.7698\n",
            "Epoch 658/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7790 - val_loss: 0.4467 - val_accuracy: 0.7914\n",
            "Epoch 659/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7862 - val_loss: 0.4504 - val_accuracy: 0.7698\n",
            "Epoch 660/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7826 - val_loss: 0.4587 - val_accuracy: 0.7698\n",
            "Epoch 661/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7826 - val_loss: 0.4554 - val_accuracy: 0.7698\n",
            "Epoch 662/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7790 - val_loss: 0.4511 - val_accuracy: 0.7698\n",
            "Epoch 663/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7862 - val_loss: 0.4483 - val_accuracy: 0.7698\n",
            "Epoch 664/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7862 - val_loss: 0.4639 - val_accuracy: 0.7626\n",
            "Epoch 665/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7790 - val_loss: 0.4522 - val_accuracy: 0.7698\n",
            "Epoch 666/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7826 - val_loss: 0.4441 - val_accuracy: 0.7986\n",
            "Epoch 667/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7862 - val_loss: 0.4499 - val_accuracy: 0.7698\n",
            "Epoch 668/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7844 - val_loss: 0.4576 - val_accuracy: 0.7698\n",
            "Epoch 669/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7844 - val_loss: 0.4557 - val_accuracy: 0.7698\n",
            "Epoch 670/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7790 - val_loss: 0.4524 - val_accuracy: 0.7698\n",
            "Epoch 671/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7790 - val_loss: 0.4500 - val_accuracy: 0.7698\n",
            "Epoch 672/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7808 - val_loss: 0.4569 - val_accuracy: 0.7698\n",
            "Epoch 673/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7790 - val_loss: 0.4531 - val_accuracy: 0.7698\n",
            "Epoch 674/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7862 - val_loss: 0.4596 - val_accuracy: 0.7698\n",
            "Epoch 675/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7880 - val_loss: 0.4618 - val_accuracy: 0.7626\n",
            "Epoch 676/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7808 - val_loss: 0.4624 - val_accuracy: 0.7626\n",
            "Epoch 677/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7880 - val_loss: 0.4478 - val_accuracy: 0.7698\n",
            "Epoch 678/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7826 - val_loss: 0.4521 - val_accuracy: 0.7698\n",
            "Epoch 679/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7899 - val_loss: 0.4545 - val_accuracy: 0.7698\n",
            "Epoch 680/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7826 - val_loss: 0.4485 - val_accuracy: 0.7698\n",
            "Epoch 681/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7772 - val_loss: 0.4498 - val_accuracy: 0.7698\n",
            "Epoch 682/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7862 - val_loss: 0.4474 - val_accuracy: 0.7698\n",
            "Epoch 683/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7880 - val_loss: 0.4639 - val_accuracy: 0.7698\n",
            "Epoch 684/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7880 - val_loss: 0.4566 - val_accuracy: 0.7698\n",
            "Epoch 685/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.4448 - val_accuracy: 0.7914\n",
            "Epoch 686/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.4553 - val_accuracy: 0.7698\n",
            "Epoch 687/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7862 - val_loss: 0.4518 - val_accuracy: 0.7698\n",
            "Epoch 688/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7844 - val_loss: 0.4525 - val_accuracy: 0.7698\n",
            "Epoch 689/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7826 - val_loss: 0.4451 - val_accuracy: 0.7914\n",
            "Epoch 690/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7808 - val_loss: 0.4441 - val_accuracy: 0.7986\n",
            "Epoch 691/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7826 - val_loss: 0.4478 - val_accuracy: 0.7698\n",
            "Epoch 692/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7826 - val_loss: 0.4456 - val_accuracy: 0.7842\n",
            "Epoch 693/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7826 - val_loss: 0.4457 - val_accuracy: 0.7842\n",
            "Epoch 694/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7862 - val_loss: 0.4515 - val_accuracy: 0.7698\n",
            "Epoch 695/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7844 - val_loss: 0.4532 - val_accuracy: 0.7698\n",
            "Epoch 696/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7935 - val_loss: 0.4653 - val_accuracy: 0.7698\n",
            "Epoch 697/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7826 - val_loss: 0.4587 - val_accuracy: 0.7698\n",
            "Epoch 698/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7808 - val_loss: 0.4574 - val_accuracy: 0.7698\n",
            "Epoch 699/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7772 - val_loss: 0.4467 - val_accuracy: 0.7698\n",
            "Epoch 700/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.4543 - val_accuracy: 0.7698\n",
            "Epoch 701/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.4487 - val_accuracy: 0.7698\n",
            "Epoch 702/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7844 - val_loss: 0.4463 - val_accuracy: 0.7842\n",
            "Epoch 703/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7826 - val_loss: 0.4605 - val_accuracy: 0.7770\n",
            "Epoch 704/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.4622 - val_accuracy: 0.7770\n",
            "Epoch 705/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7844 - val_loss: 0.4541 - val_accuracy: 0.7698\n",
            "Epoch 706/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7808 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 707/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7790 - val_loss: 0.4570 - val_accuracy: 0.7698\n",
            "Epoch 708/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7862 - val_loss: 0.4575 - val_accuracy: 0.7698\n",
            "Epoch 709/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7808 - val_loss: 0.4494 - val_accuracy: 0.7698\n",
            "Epoch 710/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7844 - val_loss: 0.4626 - val_accuracy: 0.7770\n",
            "Epoch 711/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7790 - val_loss: 0.4517 - val_accuracy: 0.7698\n",
            "Epoch 712/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7917 - val_loss: 0.4541 - val_accuracy: 0.7698\n",
            "Epoch 713/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7844 - val_loss: 0.4528 - val_accuracy: 0.7698\n",
            "Epoch 714/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7844 - val_loss: 0.4546 - val_accuracy: 0.7698\n",
            "Epoch 715/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7826 - val_loss: 0.4503 - val_accuracy: 0.7698\n",
            "Epoch 716/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7808 - val_loss: 0.4564 - val_accuracy: 0.7698\n",
            "Epoch 717/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7790 - val_loss: 0.4594 - val_accuracy: 0.7770\n",
            "Epoch 718/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7826 - val_loss: 0.4559 - val_accuracy: 0.7698\n",
            "Epoch 719/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7862 - val_loss: 0.4556 - val_accuracy: 0.7698\n",
            "Epoch 720/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7880 - val_loss: 0.4520 - val_accuracy: 0.7698\n",
            "Epoch 721/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7826 - val_loss: 0.4546 - val_accuracy: 0.7698\n",
            "Epoch 722/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.4428 - val_accuracy: 0.7986\n",
            "Epoch 723/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7862 - val_loss: 0.4428 - val_accuracy: 0.7986\n",
            "Epoch 724/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.4557 - val_accuracy: 0.7770\n",
            "Epoch 725/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7826 - val_loss: 0.4582 - val_accuracy: 0.7770\n",
            "Epoch 726/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7862 - val_loss: 0.4466 - val_accuracy: 0.7770\n",
            "Epoch 727/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7844 - val_loss: 0.4563 - val_accuracy: 0.7698\n",
            "Epoch 728/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7880 - val_loss: 0.4519 - val_accuracy: 0.7698\n",
            "Epoch 729/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7844 - val_loss: 0.4432 - val_accuracy: 0.7986\n",
            "Epoch 730/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7790 - val_loss: 0.4564 - val_accuracy: 0.7770\n",
            "Epoch 731/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7790 - val_loss: 0.4665 - val_accuracy: 0.7770\n",
            "Epoch 732/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7862 - val_loss: 0.4513 - val_accuracy: 0.7698\n",
            "Epoch 733/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7772 - val_loss: 0.4388 - val_accuracy: 0.7914\n",
            "Epoch 734/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7862 - val_loss: 0.4589 - val_accuracy: 0.7770\n",
            "Epoch 735/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7880 - val_loss: 0.4519 - val_accuracy: 0.7698\n",
            "Epoch 736/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7808 - val_loss: 0.4548 - val_accuracy: 0.7698\n",
            "Epoch 737/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7844 - val_loss: 0.4469 - val_accuracy: 0.7698\n",
            "Epoch 738/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7844 - val_loss: 0.4532 - val_accuracy: 0.7698\n",
            "Epoch 739/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7844 - val_loss: 0.4460 - val_accuracy: 0.7770\n",
            "Epoch 740/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7844 - val_loss: 0.4437 - val_accuracy: 0.7914\n",
            "Epoch 741/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7880 - val_loss: 0.4531 - val_accuracy: 0.7698\n",
            "Epoch 742/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7826 - val_loss: 0.4509 - val_accuracy: 0.7698\n",
            "Epoch 743/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7844 - val_loss: 0.4521 - val_accuracy: 0.7698\n",
            "Epoch 744/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7826 - val_loss: 0.4481 - val_accuracy: 0.7698\n",
            "Epoch 745/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7899 - val_loss: 0.4488 - val_accuracy: 0.7698\n",
            "Epoch 746/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7844 - val_loss: 0.4508 - val_accuracy: 0.7698\n",
            "Epoch 747/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7844 - val_loss: 0.4501 - val_accuracy: 0.7698\n",
            "Epoch 748/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.4600 - val_accuracy: 0.7770\n",
            "Epoch 749/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7826 - val_loss: 0.4483 - val_accuracy: 0.7698\n",
            "Epoch 750/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.4557 - val_accuracy: 0.7770\n",
            "Epoch 751/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7844 - val_loss: 0.4578 - val_accuracy: 0.7770\n",
            "Epoch 752/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7917 - val_loss: 0.4439 - val_accuracy: 0.7842\n",
            "Epoch 753/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7844 - val_loss: 0.4462 - val_accuracy: 0.7770\n",
            "Epoch 754/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7844 - val_loss: 0.4453 - val_accuracy: 0.7842\n",
            "Epoch 755/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7917 - val_loss: 0.4468 - val_accuracy: 0.7770\n",
            "Epoch 756/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7935 - val_loss: 0.4437 - val_accuracy: 0.7842\n",
            "Epoch 757/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7844 - val_loss: 0.4503 - val_accuracy: 0.7698\n",
            "Epoch 758/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7862 - val_loss: 0.4491 - val_accuracy: 0.7698\n",
            "Epoch 759/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7880 - val_loss: 0.4458 - val_accuracy: 0.7770\n",
            "Epoch 760/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7826 - val_loss: 0.4473 - val_accuracy: 0.7698\n",
            "Epoch 761/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7826 - val_loss: 0.4596 - val_accuracy: 0.7770\n",
            "Epoch 762/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7772 - val_loss: 0.4504 - val_accuracy: 0.7698\n",
            "Epoch 763/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7862 - val_loss: 0.4618 - val_accuracy: 0.7842\n",
            "Epoch 764/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7880 - val_loss: 0.4540 - val_accuracy: 0.7770\n",
            "Epoch 765/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7862 - val_loss: 0.4482 - val_accuracy: 0.7698\n",
            "Epoch 766/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7844 - val_loss: 0.4529 - val_accuracy: 0.7770\n",
            "Epoch 767/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7844 - val_loss: 0.4594 - val_accuracy: 0.7770\n",
            "Epoch 768/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7826 - val_loss: 0.4513 - val_accuracy: 0.7770\n",
            "Epoch 769/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7844 - val_loss: 0.4471 - val_accuracy: 0.7698\n",
            "Epoch 770/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7880 - val_loss: 0.4491 - val_accuracy: 0.7698\n",
            "Epoch 771/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7808 - val_loss: 0.4471 - val_accuracy: 0.7698\n",
            "Epoch 772/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7844 - val_loss: 0.4482 - val_accuracy: 0.7698\n",
            "Epoch 773/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7844 - val_loss: 0.4531 - val_accuracy: 0.7770\n",
            "Epoch 774/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7862 - val_loss: 0.4492 - val_accuracy: 0.7770\n",
            "Epoch 775/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.4549 - val_accuracy: 0.7770\n",
            "Epoch 776/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7790 - val_loss: 0.4485 - val_accuracy: 0.7770\n",
            "Epoch 777/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7917 - val_loss: 0.4488 - val_accuracy: 0.7770\n",
            "Epoch 778/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7808 - val_loss: 0.4495 - val_accuracy: 0.7770\n",
            "Epoch 779/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7880 - val_loss: 0.4450 - val_accuracy: 0.7842\n",
            "Epoch 780/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7862 - val_loss: 0.4538 - val_accuracy: 0.7770\n",
            "Epoch 781/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7826 - val_loss: 0.4556 - val_accuracy: 0.7770\n",
            "Epoch 782/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7844 - val_loss: 0.4463 - val_accuracy: 0.7770\n",
            "Epoch 783/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7808 - val_loss: 0.4442 - val_accuracy: 0.7842\n",
            "Epoch 784/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7772 - val_loss: 0.4445 - val_accuracy: 0.7842\n",
            "Epoch 785/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7844 - val_loss: 0.4491 - val_accuracy: 0.7770\n",
            "Epoch 786/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.4521 - val_accuracy: 0.7770\n",
            "Epoch 787/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7880 - val_loss: 0.4468 - val_accuracy: 0.7698\n",
            "Epoch 788/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7808 - val_loss: 0.4405 - val_accuracy: 0.8058\n",
            "Epoch 789/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7880 - val_loss: 0.4567 - val_accuracy: 0.7770\n",
            "Epoch 790/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7808 - val_loss: 0.4481 - val_accuracy: 0.7770\n",
            "Epoch 791/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7862 - val_loss: 0.4539 - val_accuracy: 0.7770\n",
            "Epoch 792/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7953 - val_loss: 0.4470 - val_accuracy: 0.7770\n",
            "Epoch 793/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7880 - val_loss: 0.4649 - val_accuracy: 0.7842\n",
            "Epoch 794/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7772 - val_loss: 0.4475 - val_accuracy: 0.7770\n",
            "Epoch 795/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7844 - val_loss: 0.4508 - val_accuracy: 0.7770\n",
            "Epoch 796/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7844 - val_loss: 0.4462 - val_accuracy: 0.7842\n",
            "Epoch 797/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.4493 - val_accuracy: 0.7770\n",
            "Epoch 798/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.4604 - val_accuracy: 0.7842\n",
            "Epoch 799/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7844 - val_loss: 0.4602 - val_accuracy: 0.7842\n",
            "Epoch 800/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7826 - val_loss: 0.4516 - val_accuracy: 0.7770\n",
            "Epoch 801/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7880 - val_loss: 0.4488 - val_accuracy: 0.7770\n",
            "Epoch 802/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7826 - val_loss: 0.4472 - val_accuracy: 0.7770\n",
            "Epoch 803/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4547 - val_accuracy: 0.7770\n",
            "Epoch 804/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.4460 - val_accuracy: 0.7842\n",
            "Epoch 805/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.4582 - val_accuracy: 0.7770\n",
            "Epoch 806/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7844 - val_loss: 0.4469 - val_accuracy: 0.7842\n",
            "Epoch 807/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.4518 - val_accuracy: 0.7770\n",
            "Epoch 808/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7880 - val_loss: 0.4463 - val_accuracy: 0.7842\n",
            "Epoch 809/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.4595 - val_accuracy: 0.7842\n",
            "Epoch 810/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7862 - val_loss: 0.4445 - val_accuracy: 0.7770\n",
            "Epoch 811/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7808 - val_loss: 0.4526 - val_accuracy: 0.7770\n",
            "Epoch 812/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7826 - val_loss: 0.4614 - val_accuracy: 0.7842\n",
            "Epoch 813/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7862 - val_loss: 0.4543 - val_accuracy: 0.7770\n",
            "Epoch 814/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.4491 - val_accuracy: 0.7770\n",
            "Epoch 815/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7880 - val_loss: 0.4573 - val_accuracy: 0.7842\n",
            "Epoch 816/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.4440 - val_accuracy: 0.7914\n",
            "Epoch 817/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7935 - val_loss: 0.4527 - val_accuracy: 0.7770\n",
            "Epoch 818/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7862 - val_loss: 0.4477 - val_accuracy: 0.7842\n",
            "Epoch 819/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7808 - val_loss: 0.4424 - val_accuracy: 0.7842\n",
            "Epoch 820/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7844 - val_loss: 0.4490 - val_accuracy: 0.7770\n",
            "Epoch 821/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7862 - val_loss: 0.4466 - val_accuracy: 0.7770\n",
            "Epoch 822/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7844 - val_loss: 0.4550 - val_accuracy: 0.7770\n",
            "Epoch 823/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7862 - val_loss: 0.4473 - val_accuracy: 0.7770\n",
            "Epoch 824/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7844 - val_loss: 0.4591 - val_accuracy: 0.7842\n",
            "Epoch 825/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7826 - val_loss: 0.4420 - val_accuracy: 0.7914\n",
            "Epoch 826/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.4428 - val_accuracy: 0.7914\n",
            "Epoch 827/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7862 - val_loss: 0.4533 - val_accuracy: 0.7770\n",
            "Epoch 828/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.4515 - val_accuracy: 0.7770\n",
            "Epoch 829/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7880 - val_loss: 0.4445 - val_accuracy: 0.7842\n",
            "Epoch 830/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.4493 - val_accuracy: 0.7770\n",
            "Epoch 831/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7880 - val_loss: 0.4449 - val_accuracy: 0.7842\n",
            "Epoch 832/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7953 - val_loss: 0.4531 - val_accuracy: 0.7770\n",
            "Epoch 833/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7844 - val_loss: 0.4503 - val_accuracy: 0.7770\n",
            "Epoch 834/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.4528 - val_accuracy: 0.7770\n",
            "Epoch 835/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7862 - val_loss: 0.4526 - val_accuracy: 0.7770\n",
            "Epoch 836/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7826 - val_loss: 0.4475 - val_accuracy: 0.7770\n",
            "Epoch 837/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7826 - val_loss: 0.4439 - val_accuracy: 0.7842\n",
            "Epoch 838/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7862 - val_loss: 0.4449 - val_accuracy: 0.7842\n",
            "Epoch 839/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7862 - val_loss: 0.4458 - val_accuracy: 0.7842\n",
            "Epoch 840/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7935 - val_loss: 0.4443 - val_accuracy: 0.7842\n",
            "Epoch 841/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7808 - val_loss: 0.4492 - val_accuracy: 0.7770\n",
            "Epoch 842/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7862 - val_loss: 0.4500 - val_accuracy: 0.7770\n",
            "Epoch 843/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.4438 - val_accuracy: 0.7842\n",
            "Epoch 844/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7826 - val_loss: 0.4521 - val_accuracy: 0.7770\n",
            "Epoch 845/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7862 - val_loss: 0.4566 - val_accuracy: 0.7842\n",
            "Epoch 846/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7826 - val_loss: 0.4515 - val_accuracy: 0.7770\n",
            "Epoch 847/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7935 - val_loss: 0.4484 - val_accuracy: 0.7770\n",
            "Epoch 848/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7880 - val_loss: 0.4498 - val_accuracy: 0.7770\n",
            "Epoch 849/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7862 - val_loss: 0.4508 - val_accuracy: 0.7770\n",
            "Epoch 850/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7862 - val_loss: 0.4463 - val_accuracy: 0.7842\n",
            "Epoch 851/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7844 - val_loss: 0.4507 - val_accuracy: 0.7770\n",
            "Epoch 852/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.4554 - val_accuracy: 0.7842\n",
            "Epoch 853/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7971 - val_loss: 0.4396 - val_accuracy: 0.7986\n",
            "Epoch 854/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7826 - val_loss: 0.4418 - val_accuracy: 0.7986\n",
            "Epoch 855/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7880 - val_loss: 0.4450 - val_accuracy: 0.7842\n",
            "Epoch 856/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7880 - val_loss: 0.4464 - val_accuracy: 0.7842\n",
            "Epoch 857/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7844 - val_loss: 0.4484 - val_accuracy: 0.7770\n",
            "Epoch 858/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.4571 - val_accuracy: 0.7842\n",
            "Epoch 859/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7880 - val_loss: 0.4490 - val_accuracy: 0.7770\n",
            "Epoch 860/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.4396 - val_accuracy: 0.8058\n",
            "Epoch 861/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7880 - val_loss: 0.4507 - val_accuracy: 0.7770\n",
            "Epoch 862/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7880 - val_loss: 0.4462 - val_accuracy: 0.7842\n",
            "Epoch 863/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7862 - val_loss: 0.4438 - val_accuracy: 0.7842\n",
            "Epoch 864/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7880 - val_loss: 0.4484 - val_accuracy: 0.7770\n",
            "Epoch 865/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7844 - val_loss: 0.4539 - val_accuracy: 0.7842\n",
            "Epoch 866/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.4377 - val_accuracy: 0.7986\n",
            "Epoch 867/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7880 - val_loss: 0.4444 - val_accuracy: 0.7842\n",
            "Epoch 868/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.4442 - val_accuracy: 0.7842\n",
            "Epoch 869/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7826 - val_loss: 0.4398 - val_accuracy: 0.8058\n",
            "Epoch 870/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.4496 - val_accuracy: 0.7770\n",
            "Epoch 871/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7844 - val_loss: 0.4455 - val_accuracy: 0.7842\n",
            "Epoch 872/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7880 - val_loss: 0.4430 - val_accuracy: 0.7914\n",
            "Epoch 873/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.4480 - val_accuracy: 0.7770\n",
            "Epoch 874/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7935 - val_loss: 0.4416 - val_accuracy: 0.7986\n",
            "Epoch 875/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.4437 - val_accuracy: 0.7842\n",
            "Epoch 876/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7880 - val_loss: 0.4406 - val_accuracy: 0.7986\n",
            "Epoch 877/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7935 - val_loss: 0.4523 - val_accuracy: 0.7770\n",
            "Epoch 878/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7917 - val_loss: 0.4405 - val_accuracy: 0.7986\n",
            "Epoch 879/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7862 - val_loss: 0.4486 - val_accuracy: 0.7770\n",
            "Epoch 880/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7844 - val_loss: 0.4549 - val_accuracy: 0.7842\n",
            "Epoch 881/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7862 - val_loss: 0.4437 - val_accuracy: 0.7842\n",
            "Epoch 882/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7862 - val_loss: 0.4458 - val_accuracy: 0.7842\n",
            "Epoch 883/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7844 - val_loss: 0.4459 - val_accuracy: 0.7770\n",
            "Epoch 884/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.4426 - val_accuracy: 0.7914\n",
            "Epoch 885/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7862 - val_loss: 0.4470 - val_accuracy: 0.7770\n",
            "Epoch 886/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7844 - val_loss: 0.4434 - val_accuracy: 0.7842\n",
            "Epoch 887/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7971 - val_loss: 0.4444 - val_accuracy: 0.7842\n",
            "Epoch 888/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7880 - val_loss: 0.4498 - val_accuracy: 0.7770\n",
            "Epoch 889/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7880 - val_loss: 0.4499 - val_accuracy: 0.7770\n",
            "Epoch 890/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7971 - val_loss: 0.4405 - val_accuracy: 0.7986\n",
            "Epoch 891/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7917 - val_loss: 0.4440 - val_accuracy: 0.7842\n",
            "Epoch 892/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.4523 - val_accuracy: 0.7770\n",
            "Epoch 893/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7826 - val_loss: 0.4484 - val_accuracy: 0.7770\n",
            "Epoch 894/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.4509 - val_accuracy: 0.7770\n",
            "Epoch 895/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.4476 - val_accuracy: 0.7770\n",
            "Epoch 896/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7844 - val_loss: 0.4501 - val_accuracy: 0.7770\n",
            "Epoch 897/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.4488 - val_accuracy: 0.7770\n",
            "Epoch 898/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.4541 - val_accuracy: 0.7842\n",
            "Epoch 899/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7880 - val_loss: 0.4511 - val_accuracy: 0.7770\n",
            "Epoch 900/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7880 - val_loss: 0.4415 - val_accuracy: 0.7986\n",
            "Epoch 901/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7880 - val_loss: 0.4470 - val_accuracy: 0.7842\n",
            "Epoch 902/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.4499 - val_accuracy: 0.7770\n",
            "Epoch 903/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7917 - val_loss: 0.4445 - val_accuracy: 0.7842\n",
            "Epoch 904/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7935 - val_loss: 0.4412 - val_accuracy: 0.7986\n",
            "Epoch 905/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7917 - val_loss: 0.4523 - val_accuracy: 0.7842\n",
            "Epoch 906/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7880 - val_loss: 0.4549 - val_accuracy: 0.7842\n",
            "Epoch 907/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7917 - val_loss: 0.4493 - val_accuracy: 0.7770\n",
            "Epoch 908/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7844 - val_loss: 0.4420 - val_accuracy: 0.7914\n",
            "Epoch 909/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7862 - val_loss: 0.4450 - val_accuracy: 0.7842\n",
            "Epoch 910/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.4482 - val_accuracy: 0.7770\n",
            "Epoch 911/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7917 - val_loss: 0.4462 - val_accuracy: 0.7770\n",
            "Epoch 912/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4491 - val_accuracy: 0.7770\n",
            "Epoch 913/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7862 - val_loss: 0.4483 - val_accuracy: 0.7770\n",
            "Epoch 914/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7880 - val_loss: 0.4503 - val_accuracy: 0.7770\n",
            "Epoch 915/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7935 - val_loss: 0.4661 - val_accuracy: 0.7914\n",
            "Epoch 916/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7935 - val_loss: 0.4456 - val_accuracy: 0.7842\n",
            "Epoch 917/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4465 - val_accuracy: 0.7842\n",
            "Epoch 918/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.4437 - val_accuracy: 0.7914\n",
            "Epoch 919/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.4425 - val_accuracy: 0.7914\n",
            "Epoch 920/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7953 - val_loss: 0.4485 - val_accuracy: 0.7770\n",
            "Epoch 921/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7880 - val_loss: 0.4535 - val_accuracy: 0.7842\n",
            "Epoch 922/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7880 - val_loss: 0.4431 - val_accuracy: 0.7914\n",
            "Epoch 923/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7880 - val_loss: 0.4417 - val_accuracy: 0.7914\n",
            "Epoch 924/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7935 - val_loss: 0.4402 - val_accuracy: 0.7986\n",
            "Epoch 925/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7880 - val_loss: 0.4473 - val_accuracy: 0.7770\n",
            "Epoch 926/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7953 - val_loss: 0.4457 - val_accuracy: 0.7842\n",
            "Epoch 927/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7880 - val_loss: 0.4444 - val_accuracy: 0.7842\n",
            "Epoch 928/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7862 - val_loss: 0.4417 - val_accuracy: 0.7914\n",
            "Epoch 929/1000\n",
            "138/138 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.4461 - val_accuracy: 0.7842\n",
            "Epoch 930/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4438 - val_accuracy: 0.7842\n",
            "Epoch 931/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7935 - val_loss: 0.4486 - val_accuracy: 0.7770\n",
            "Epoch 932/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7880 - val_loss: 0.4393 - val_accuracy: 0.7986\n",
            "Epoch 933/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7880 - val_loss: 0.4370 - val_accuracy: 0.8058\n",
            "Epoch 934/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7917 - val_loss: 0.4458 - val_accuracy: 0.7770\n",
            "Epoch 935/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7844 - val_loss: 0.4517 - val_accuracy: 0.7842\n",
            "Epoch 936/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7917 - val_loss: 0.4456 - val_accuracy: 0.7842\n",
            "Epoch 937/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.4443 - val_accuracy: 0.7842\n",
            "Epoch 938/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7844 - val_loss: 0.4499 - val_accuracy: 0.7770\n",
            "Epoch 939/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7880 - val_loss: 0.4462 - val_accuracy: 0.7770\n",
            "Epoch 940/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7880 - val_loss: 0.4485 - val_accuracy: 0.7770\n",
            "Epoch 941/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7826 - val_loss: 0.4361 - val_accuracy: 0.8058\n",
            "Epoch 942/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7826 - val_loss: 0.4400 - val_accuracy: 0.7914\n",
            "Epoch 943/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7844 - val_loss: 0.4523 - val_accuracy: 0.7842\n",
            "Epoch 944/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7808 - val_loss: 0.4528 - val_accuracy: 0.7842\n",
            "Epoch 945/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7935 - val_loss: 0.4744 - val_accuracy: 0.7698\n",
            "Epoch 946/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7880 - val_loss: 0.4527 - val_accuracy: 0.7842\n",
            "Epoch 947/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.4470 - val_accuracy: 0.7770\n",
            "Epoch 948/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.4442 - val_accuracy: 0.7842\n",
            "Epoch 949/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7935 - val_loss: 0.4458 - val_accuracy: 0.7770\n",
            "Epoch 950/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7935 - val_loss: 0.4563 - val_accuracy: 0.7914\n",
            "Epoch 951/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7826 - val_loss: 0.4449 - val_accuracy: 0.7842\n",
            "Epoch 952/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.4504 - val_accuracy: 0.7842\n",
            "Epoch 953/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7880 - val_loss: 0.4503 - val_accuracy: 0.7842\n",
            "Epoch 954/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7880 - val_loss: 0.4480 - val_accuracy: 0.7842\n",
            "Epoch 955/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7953 - val_loss: 0.4584 - val_accuracy: 0.7914\n",
            "Epoch 956/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7880 - val_loss: 0.4428 - val_accuracy: 0.7914\n",
            "Epoch 957/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.4459 - val_accuracy: 0.7770\n",
            "Epoch 958/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4457 - val_accuracy: 0.7770\n",
            "Epoch 959/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.4467 - val_accuracy: 0.7770\n",
            "Epoch 960/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.4486 - val_accuracy: 0.7842\n",
            "Epoch 961/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.4394 - val_accuracy: 0.7914\n",
            "Epoch 962/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7862 - val_loss: 0.4487 - val_accuracy: 0.7842\n",
            "Epoch 963/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7862 - val_loss: 0.4478 - val_accuracy: 0.7770\n",
            "Epoch 964/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.4411 - val_accuracy: 0.7914\n",
            "Epoch 965/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7862 - val_loss: 0.4410 - val_accuracy: 0.7914\n",
            "Epoch 966/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7880 - val_loss: 0.4392 - val_accuracy: 0.7914\n",
            "Epoch 967/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7971 - val_loss: 0.4484 - val_accuracy: 0.7842\n",
            "Epoch 968/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7880 - val_loss: 0.4496 - val_accuracy: 0.7842\n",
            "Epoch 969/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7844 - val_loss: 0.4412 - val_accuracy: 0.7914\n",
            "Epoch 970/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7880 - val_loss: 0.4417 - val_accuracy: 0.7914\n",
            "Epoch 971/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7953 - val_loss: 0.4411 - val_accuracy: 0.7914\n",
            "Epoch 972/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7953 - val_loss: 0.4409 - val_accuracy: 0.7914\n",
            "Epoch 973/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4417 - val_accuracy: 0.7914\n",
            "Epoch 974/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.4390 - val_accuracy: 0.7986\n",
            "Epoch 975/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7953 - val_loss: 0.4418 - val_accuracy: 0.7914\n",
            "Epoch 976/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7880 - val_loss: 0.4447 - val_accuracy: 0.7770\n",
            "Epoch 977/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7935 - val_loss: 0.4542 - val_accuracy: 0.7914\n",
            "Epoch 978/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7862 - val_loss: 0.4579 - val_accuracy: 0.7914\n",
            "Epoch 979/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7880 - val_loss: 0.4481 - val_accuracy: 0.7842\n",
            "Epoch 980/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7862 - val_loss: 0.4443 - val_accuracy: 0.7842\n",
            "Epoch 981/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.4348 - val_accuracy: 0.8058\n",
            "Epoch 982/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7989 - val_loss: 0.4329 - val_accuracy: 0.8058\n",
            "Epoch 983/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7862 - val_loss: 0.4424 - val_accuracy: 0.7914\n",
            "Epoch 984/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7953 - val_loss: 0.4435 - val_accuracy: 0.7914\n",
            "Epoch 985/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.4463 - val_accuracy: 0.7842\n",
            "Epoch 986/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7880 - val_loss: 0.4392 - val_accuracy: 0.7914\n",
            "Epoch 987/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4421 - val_accuracy: 0.7914\n",
            "Epoch 988/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.4421 - val_accuracy: 0.7914\n",
            "Epoch 989/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.4414 - val_accuracy: 0.7914\n",
            "Epoch 990/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4440 - val_accuracy: 0.7914\n",
            "Epoch 991/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7953 - val_loss: 0.4452 - val_accuracy: 0.7842\n",
            "Epoch 992/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.7953 - val_loss: 0.4390 - val_accuracy: 0.7914\n",
            "Epoch 993/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7935 - val_loss: 0.4528 - val_accuracy: 0.7914\n",
            "Epoch 994/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7826 - val_loss: 0.4435 - val_accuracy: 0.7914\n",
            "Epoch 995/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7935 - val_loss: 0.4522 - val_accuracy: 0.7914\n",
            "Epoch 996/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.4454 - val_accuracy: 0.7842\n",
            "Epoch 997/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.4466 - val_accuracy: 0.7842\n",
            "Epoch 998/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7880 - val_loss: 0.4437 - val_accuracy: 0.7842\n",
            "Epoch 999/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7880 - val_loss: 0.4526 - val_accuracy: 0.7914\n",
            "Epoch 1000/1000\n",
            "138/138 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4425 - val_accuracy: 0.7914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "b70baefa-2a51-41f5-aa9d-3d7cc35728ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "ad3f55cf-19c8-4723-9413-f4f033ad9df4"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.6169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "0c3aefb0-7c62-4a7b-e51e-31e574e6630d"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5559551, 0.4440449]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "37bfaf93-01c4-4dc7-8cc8-340ca70f52d4"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}